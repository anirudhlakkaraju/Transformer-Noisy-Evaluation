{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234673,"status":"ok","timestamp":1684337648489,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"h-t39GWCNkXO","outputId":"4f5b506f-1a99-47ad-aa33-df0edc633dc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KbhyWqs0kAOq","outputId":"609623d0-d25c-4d05-a47e-eecc5d34951c","executionInfo":{"status":"ok","timestamp":1684337761531,"user_tz":240,"elapsed":31908,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}],"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","!pip install sentencepiece\n","!pip install nlpaug"]},{"cell_type":"markdown","source":["###Imports"],"metadata":{"id":"-b0Kh7PFMO9q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFyllB4kRQct"},"outputs":[],"source":["# Import required libraries\n","import torch\n","import pandas as pd\n","import numpy as np\n","import re\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, f1_score\n","import random\n","from tqdm.auto import tqdm\n","import random\n","import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1684337790231,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"VJUs_qRSP9YO","outputId":"feba02be-ed6d-4ed8-b4ab-edfd43eed616"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}],"source":["import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")\n"]},{"cell_type":"code","source":["def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)"],"metadata":{"id":"a0REebhaMhbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTFvVgIZQjk6","executionInfo":{"status":"ok","timestamp":1684338075256,"user_tz":240,"elapsed":285040,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"056c674d-0396-4ae1-977f-28b6e1b4a8b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","success!\n","helper file downloaded! (helpers.py)\n"]}],"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')\n","\n","import os\n","import zipfile\n","\n","# Download helper functions file\n","helper_file = drive.CreateFile({'id': '16HW-z9Y1tM3gZ_vFpJAuwUDohz91Aac-'})\n","helper_file.GetContentFile('helpers.py')\n","print('helper file downloaded! (helpers.py)')\n","\n"]},{"cell_type":"markdown","source":["### Data download and preprocessing"],"metadata":{"id":"FSf542_wMTjp"}},{"cell_type":"code","source":["import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def clean_text(text):\n","    # Convert all text to lowercase\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    # Remove numbers\n","    text = re.sub(r'\\d+', '', text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = nltk.word_tokenize(text)\n","    tokens = [token for token in tokens if token not in stop_words]\n","    text = ' '.join(tokens)\n","\n","    # Remove extra whitespaces\n","    text = re.sub(' +', ' ', text)\n","\n","    return text"],"metadata":{"id":"hkiufbTtM3Kr","executionInfo":{"status":"ok","timestamp":1684338076362,"user_tz":240,"elapsed":1121,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"67c2ff23-edf8-4ba7-bef3-008e0d0e8b2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-FypXfWQ0iN"},"outputs":[],"source":["from helpers import tokenize_and_format, flat_accuracy\n","\n","df = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","df = df.rename(columns={'review':'text'})\n","df = df[['text', 'sentiment']]\n","\n","# How much of the dataset to use\n","data_size = 0.2\n","df = df.sample(frac=data_size, random_state=42)\n","\n","df['text'] = df['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","df['sentiment'] = df['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = df[df['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","df.drop(empty_rows.index, inplace=True)"]},{"cell_type":"markdown","source":["### Train/val/test splits"],"metadata":{"id":"r3JNeLHnNl04"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxjCvi_Ids5O"},"outputs":[],"source":["# Separate the dataset into three subsets based on the sentiment labels\n","positive_reviews = df[df['sentiment'] == sentiment_map['positive']]\n","negative_reviews = df[df['sentiment'] == sentiment_map['negative']]\n","\n","# Shuffle each of the two subsets randomly\n","positive_reviews = positive_reviews.sample(frac=1, random_state=42)\n","negative_reviews = negative_reviews.sample(frac=1, random_state=42)\n","\n","# Divide each subset into training, validation, and test sets with a 70/20/10 ratio\n","train_pos, val_pos_test_pos = train_test_split(positive_reviews, test_size=0.3, random_state=42)\n","val_pos, test_pos = train_test_split(val_pos_test_pos, test_size=0.33, random_state=42)\n","\n","train_neg, val_neg_test_neg = train_test_split(negative_reviews, test_size=0.3, random_state=42)\n","val_neg, test_neg = train_test_split(val_neg_test_neg, test_size=0.33, random_state=42)\n","\n","# Merge the corresponding subsets from each sentiment back together to form the final training, validation, and test sets\n","train_set = pd.concat([train_pos, train_neg], ignore_index=True)\n","val_set = pd.concat([val_pos, val_neg], ignore_index=True)\n","test_set = pd.concat([test_pos, test_neg], ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w59g7FkaSiLU","executionInfo":{"status":"ok","timestamp":1684338154161,"user_tz":240,"elapsed":56685,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["07880a5fb78144869190f7489e2daff4","359aebc9ba8a4643aa4218abf49827ca","01d670a7af914f4db15793ec527496c6","128f7324eebe4e8c89c6ca53f2434f07","dbefc1ebe6c746df9c672040a8a517b3","af75a7912042443f9331398da314660e","f4f7dec25e954aca8f3593f159cd70fd","63adb979f3da4c8cbeb561cf7c7f66d5","bfa04876dc7a489093f377abd7b9d601","9a184cce7e15420dbdeddcd96d04a9eb","57e1d047c47e4f0b8de792ac4068f6fe","acc7941e26c24d9c8eee3265b2726566","4383a0e023564760876896b3848c87da","885824d1e2444552b1dab269504201b5","6d51b1ee6e8d48e4937cf9b6a96b7b4f","bf0f955fc7ca4e8f9bd8cc7f7bbe8716","b4bc847a46984b2ba652ffecb78795bb","382cccac73224227af6f11b59d77f219","d7d7e4ba76cf44839f1149b2af058213","33178c34aa0443e6873a2903e195df16","35172b7700924081bcba71821888c093","21e67b2f267146ec952a3c20c7148de3","8a670af518414d50943798ed21e3f82d","a5cb6a15f2ad439387b19ab43b9ccf85","21e3b92dcd2748f98e607431df0c7780","6b589e7d0eaf4363998d4344842a38db","e7c742c49b7446cd8ab0c431a8954770","4997f66720fa41cf924121f036406e7e","f6397d18e1664415a39780b93842c99c","69d30fad19424e12b9d72ee4064235c4","11fe4f655b504888b7704d568c38d389","f21aa3751d314d3d941927fedef886b9","02685b7aee1c4150b83e847410d8e4ee"]},"outputId":"c87a9b68-d981-4d8b-b636-f6725e29ef2e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07880a5fb78144869190f7489e2daff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acc7941e26c24d9c8eee3265b2726566"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a670af518414d50943798ed21e3f82d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original:  saw mill valley film festival hard believe ms bloms directorial debut beautifully paced performed large cast characters could anne tyler novel ie layered back story potential futures false notes surprising bursts humor amidst selfinflicted anxiety real earthshattering dilemmas saw best youth recognize well drawn characters small moments even story moves briskly along really hope gets distribution usa live fairly sophisticated film market yet rarely get swedish films kind\n","Token IDs: tensor([[  101,  2387,  4971,  3028,  2143,  2782,  2524,  2903,  5796,  1038,\n","         21297,  2015, 21635,  2834, 17950, 13823,  2864,  2312,  3459,  3494,\n","          2071,  4776,  7482,  3117, 29464, 21323,  2067,  2466,  4022, 17795,\n","          6270,  3964, 11341, 19239,  8562, 17171,  2969,  2378, 29301,  2098,\n","         10089,  2613,  3011,  7377, 19567, 21883,  2015,  2387,  2190,  3360,\n","          6807,  2092,  4567,  3494,  2235,  5312,  2130,  2466,  5829, 28022,\n","          2135,  2247,  2428,   102]])\n"]}],"source":["# tokenize train, test and val individually\n","# For train\n","\n","texts = train_set.text.values\n","labels = train_set.sentiment.values\n","\n","# tokenize_and_format() is a helper function provided in helpers.py\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_train = torch.cat(input_ids, dim=0)\n","attention_masks_train = torch.cat(attention_masks, dim=0)\n","labels_train = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-u5LOvBTcs5","executionInfo":{"status":"ok","timestamp":1684338159113,"user_tz":240,"elapsed":4988,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d3e6d48-945c-4e38-ff0f-802401ea8046"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  one movies dont require brain thinking funny time pass forgot next hour really surprised john abrahams acting usually playing gangster like character emotionless faceso playing complete opposite successfullyby managing shine amongst comic geniuses paresh rawal akshaye kumar also quite surprised akshayes girls roles dont require much talent mostly moaning akshayes dissapearenceto girls surprised managed establish actual persona could differentiate good thing also majority songs goodit colourful fun boring sunday evening sure lighten mood\n","Token IDs: tensor([[  101,  2028,  5691,  2123,  2102,  5478,  4167,  3241,  6057,  2051,\n","          3413,  9471,  2279,  3178,  2428,  4527,  2198,  8181,  2015,  3772,\n","          2788,  2652, 20067,  2066,  2839,  7603,  3238,  5344,  2080,  2652,\n","          3143,  4500,  5147,  3762,  6605, 12342,  5921,  5021, 11067,  2229,\n","         11968,  9953,  6315,  2389, 17712,  7377,  6672,  9600,  2036,  3243,\n","          4527, 17712,  7377, 23147,  3057,  4395,  2123,  2102,  5478,  2172,\n","          5848,  3262, 22653,   102]])\n"]}],"source":["# For test\n","texts = test_set.text.values\n","labels = test_set.sentiment.values\n","\n","# tokenize_and_format() is a helper function provided in helpers.py\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids, dim=0)\n","attention_masks_test = torch.cat(attention_masks, dim=0)\n","labels_test = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQDvnkEBTpV9","executionInfo":{"status":"ok","timestamp":1684338166653,"user_tz":240,"elapsed":7545,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f7cfbd8-9bbc-4f96-e4db-93d6e055473b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  govind nihalanis directorial venture vijay tendulkars novel brilliant om puri plays inspector velankar forced protect underworld rama shetty played brilliantly sadahiv amrapurkar govind nihlans talked movie good classic film smita patil plays female lead opposite om puri naseeruddin shah brilliant cameo role although sadashiv amrapurkar scenes movie dominates movie sadashiv amrapurkars acting debutom puri national award film best actor filmfare award winner best filmstorysupporting actorsadashiv amrapurkar\n","Token IDs: tensor([[  101, 18079, 22254,  9152, 19531,  8977, 21635,  6957, 17027,  7166,\n","          5313,  6673,  2015,  3117,  8235, 18168, 16405,  3089,  3248,  7742,\n","          2310,  5802,  6673,  3140,  4047, 13607, 14115,  2016, 15353,  2209,\n","          8235,  2135,  6517,  4430, 12848,  2572,  2527,  5311,  6673, 18079,\n","         22254,  9152,  7317,  6962,  5720,  3185,  2204,  4438,  2143, 15488,\n","          6590,  6986,  4014,  3248,  2931,  2599,  4500, 18168, 16405,  3089,\n","         17235, 11510, 17375,   102]])\n"]}],"source":["# For val\n","texts = val_set.text.values\n","labels = val_set.sentiment.values\n","\n","# tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_val = torch.cat(input_ids, dim=0)\n","attention_masks_val = torch.cat(attention_masks, dim=0)\n","labels_val = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyYzcjXzT7e9","executionInfo":{"status":"ok","timestamp":1684338166653,"user_tz":240,"elapsed":17,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cd29a89-fa45-45aa-84d1-0e216d6f868d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Set Size:  6999\n","Validation Set Size:  2010\n","Test Set Size:  991\n"]}],"source":["#printing out len of train,test val\n","total = len(df)\n","num_train = len(train_set)\n","num_val = len(val_set)\n","num_test = len(test_set)\n","\n","print('Train Set Size: ',num_train)\n","print('Validation Set Size: ',num_val)\n","print('Test Set Size: ',num_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDKpkqDyXwg4"},"outputs":[],"source":["# make lists of 3-tuples \n","train_dataset=[]\n","for i in range(num_train):\n","  train_dataset.append((input_ids_train[i], attention_masks_train[i], labels_train[i]))\n","\n","val_dataset=[]\n","for i in range(num_val):\n","  val_dataset.append((input_ids_val[i], attention_masks_val[i], labels_val[i]))\n","\n","test_dataset=[]\n","for i in range(num_test):\n","  test_dataset.append((input_ids_test[i], attention_masks_test[i], labels_test[i]))\n"]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"hpzmG9IMOEQm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSu09pqLTEZo","executionInfo":{"status":"ok","timestamp":1684338178259,"user_tz":240,"elapsed":11491,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/","height":191,"referenced_widgets":["35f56c2801404e8ebd9898f8973a073f","5238ac4530154bc3ae0b74bdf42ee8cd","4530cdef24ad4d06a9d43bc26b6914c4","f28826c71fa343888eef655bd802bbe3","72e2bb34daca43efb998632dc941ad01","b292a6796a6243bf8f199db8a8b3cabb","17e0c38a1ca946e7ba104726677b52c2","09dbedad37214a76a965d4ba7def7769","06fc5a247b1f4094b1d9a8fd9233d1e7","ab79a31327b546dfbd7926d16f73dc8b","f11399b9126c4ce381f0672e65f137e5"]},"outputId":"7ecf7692-f898-43cd-950f-fbd1491ac4b2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35f56c2801404e8ebd9898f8973a073f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Define the BERT model for sequence classification\n","\n","\n","\n","\n","\n","\n","\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()\n","\n","# Set the optimizer and learning rate scheduler\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","total_steps = len(train_dataset) * 4\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"2OxQEBsQXfko","executionInfo":{"status":"ok","timestamp":1684338178260,"user_tz":240,"elapsed":18,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"outputId":"97b76e62-a1c0-4544-8b69-2a80c7ba5dbb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Define the training loop\\nmodel.to(device)\\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\\nbest_val_loss = float(\"inf\")\\nnum_epochs = 2\\ntrain_loss = []\\nval_loss = []\\nfor epoch in range(num_epochs):\\n  # Train the model\\n  model.train()\\n  epoch_loss = 0\\n\\n  train_loop = tqdm(train_loader, desc=f\\'Training Epoch {epoch+1}\\', leave=True)\\n\\n  for batch in train_loop:\\n      \\n    inputs = {\\'input_ids\\': batch[0].to(device),\\n              \\'attention_mask\\': batch[1].to(device),\\n              \\'labels\\': batch[2].to(device)}\\n    optimizer.zero_grad()\\n    outputs = model(**inputs)\\n    loss = outputs[0]\\n\\n    loss.backward()\\n    optimizer.step()\\n    scheduler.step()\\n\\n    epoch_loss += loss.item()\\n    train_loop.set_postfix(loss=loss.item())\\n\\n  epoch_loss /= len(train_loader)\\n  train_loss.append(epoch_loss)\\n\\n  # Evaluate the model on the validation set\\n  model.eval()\\n  val_preds = []\\n  val_labels = []\\n  epoch_val_loss = 0\\n\\n  with torch.no_grad():\\n    for batch in val_loader:\\n        \\n      inputs = {\\'input_ids\\': batch[0].to(device),\\n                \\'attention_mask\\': batch[1].to(device),\\n                \\'labels\\': batch[2].to(device)}\\n      \\n      outputs = model(**inputs)\\n      loss = outputs[0]\\n      epoch_val_loss += loss.item()\\n\\n      logits = outputs[1]\\n      preds = torch.argmax(logits, axis=1)\\n      val_preds.extend(preds.cpu().numpy())\\n      val_labels.extend(batch[2].cpu().numpy())\\n\\n    epoch_val_loss /= len(val_loader)\\n\\n  if epoch_val_loss < best_val_loss:\\n    best_val_loss = epoch_val_loss\\n    \\n    path = \\'/content/gdrive/MyDrive/NLP Project/models/BERT_SA_clean100\\'\\n\\n    torch.save(model.state_dict(), path+\\'/model_parameters.pth\\')\\n\\n  # Compute the evaluation metrics\\n  val_accuracy = accuracy_score(val_labels, val_preds)\\n  val_report = classification_report(val_labels, val_preds, target_names=[\\'positive\\', \\'negative\\'])\\n  \\n\\n  # Print the results for the current epoch\\n  print(\\'Epoch:\\', epoch+1, \\', Training Loss:\\', epoch_loss/len(train_loader), \\', Validation Loss:\\', epoch_val_loss, \\', Validation Accuracy:\\', val_accuracy)\\n  print(\\'Validation Classification Report:\\')\\n  print(val_report)\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["#Commented fine tuning code for testing\n","\n","'''# Define the training loop\n","model.to(device)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n","best_val_loss = float(\"inf\")\n","num_epochs = 2\n","train_loss = []\n","val_loss = []\n","for epoch in range(num_epochs):\n","  # Train the model\n","  model.train()\n","  epoch_loss = 0\n","\n","  train_loop = tqdm(train_loader, desc=f'Training Epoch {epoch+1}', leave=True)\n","\n","  for batch in train_loop:\n","      \n","    inputs = {'input_ids': batch[0].to(device),\n","              'attention_mask': batch[1].to(device),\n","              'labels': batch[2].to(device)}\n","    optimizer.zero_grad()\n","    outputs = model(**inputs)\n","    loss = outputs[0]\n","\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    epoch_loss += loss.item()\n","    train_loop.set_postfix(loss=loss.item())\n","\n","  epoch_loss /= len(train_loader)\n","  train_loss.append(epoch_loss)\n","\n","  # Evaluate the model on the validation set\n","  model.eval()\n","  val_preds = []\n","  val_labels = []\n","  epoch_val_loss = 0\n","\n","  with torch.no_grad():\n","    for batch in val_loader:\n","        \n","      inputs = {'input_ids': batch[0].to(device),\n","                'attention_mask': batch[1].to(device),\n","                'labels': batch[2].to(device)}\n","      \n","      outputs = model(**inputs)\n","      loss = outputs[0]\n","      epoch_val_loss += loss.item()\n","\n","      logits = outputs[1]\n","      preds = torch.argmax(logits, axis=1)\n","      val_preds.extend(preds.cpu().numpy())\n","      val_labels.extend(batch[2].cpu().numpy())\n","\n","    epoch_val_loss /= len(val_loader)\n","\n","  if epoch_val_loss < best_val_loss:\n","    best_val_loss = epoch_val_loss\n","    \n","    path = '/content/gdrive/MyDrive/NLP Project/models/BERT_SA_clean100'\n","\n","    torch.save(model.state_dict(), path+'/model_parameters.pth')\n","\n","  # Compute the evaluation metrics\n","  val_accuracy = accuracy_score(val_labels, val_preds)\n","  val_report = classification_report(val_labels, val_preds, target_names=['positive', 'negative'])\n","  \n","\n","  # Print the results for the current epoch\n","  print('Epoch:', epoch+1, ', Training Loss:', epoch_loss/len(train_loader), ', Validation Loss:', epoch_val_loss, ', Validation Accuracy:', val_accuracy)\n","  print('Validation Classification Report:')\n","  print(val_report)\n","    '''"]},{"cell_type":"markdown","source":["##Evaluation"],"metadata":{"id":"sngr5RhHN5_8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcPJWMs-ekqj","executionInfo":{"status":"ok","timestamp":1684338184189,"user_tz":240,"elapsed":5934,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c64200d7-1d31-44b6-d874-a7f30bea7820"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":17}],"source":["#Load model for evaluations, comment for finetuning\n","\n","path = '/content/gdrive/MyDrive/NLP Project/models/BERT_SA_clean100'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth'))"]},{"cell_type":"code","source":["# Move input tensors to the same device as the model\n","input_ids_test = input_ids_test.to(device)\n","attention_masks_test = attention_masks_test.to(device)\n","labels_test = labels_test.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids=input_ids_test, attention_mask=attention_masks_test)\n","    logits = outputs.logits\n","\n","# Apply softmax to obtain probabilities\n","probs = torch.softmax(logits, dim=1)\n","preds = torch.argmax(probs, dim=1)\n","\n","# Move predictions and labels back to CPU for evaluation\n","preds = preds.detach().cpu().numpy()\n","labels_test = labels_test.cpu().numpy()\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(labels_test, preds)\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n","# Calculate F1 score\n","f1 = f1_score(labels_test, preds, average='weighted')\n","print(f'F1 Score: {f1:.4f}')\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GP2kTwYUPGSV","executionInfo":{"status":"ok","timestamp":1684259734821,"user_tz":240,"elapsed":5633,"user":{"displayName":"Anirudh Lakkaraju","userId":"00003645168364578969"}},"outputId":"69b268dc-75cb-4e53-abb9-155b679a2072"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.8032\n","F1 Score: 0.8032\n"]}]},{"cell_type":"markdown","source":["### Evaluation on Noisy Data"],"metadata":{"id":"Lu_FsqeHRzDl"}},{"cell_type":"code","source":["# Noise funcs \n","\n","char_action = ['insert',\n","        'substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","word_action = ['substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","\n","def get_action(type):\n","  if type==\"char\":\n","    return random.choice(char_action)\n","  elif type==\"word\":\n","    return random.choice(word_action)\n","\n","\n","def augment_tweet(tweet, p=0.7):\n","    \"\"\"\n","    Augment a tweet with character-level and word-level noise.\n","\n","    Args:\n","        tweet (str): The original tweet.\n","        p (float): The probability of applying the char level augmentation.\n","\n","    Returns:\n","        str: The augmented tweet.\n","    \"\"\"\n","    # Define a list of character-level augmentation techniques\n","    char_augmenters = [\n","        nac.OcrAug(),\n","        nac.KeyboardAug(aug_char_p=0.2, aug_word_p=0.2, include_special_char=False),\n","        nac.RandomCharAug(action=get_action(\"char\"), aug_char_p=0.1, aug_word_p=0.1),\n","    ]\n","\n","    # Define a list of word-level augmentation techniques\n","    word_augmenters = [\n","        naw.SpellingAug(),\n","        naw.SplitAug(),\n","        naw.SynonymAug(),\n","        naw.RandomWordAug(aug_p=0.2, action=get_action(\"word\")),\n","    ]\n","\n","    # Randomly apply a character-level or word-level augmentation with probability p\n","    if random.random() < p:\n","        aug = random.choice(char_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","    else:\n","        aug = random.choice(word_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","        \n","    return augmented_tweet\n","\n","def add_noise(df, augmentation_percentage, task):\n","\n","  if task==\"sentiment_analysis\":\n","    # Sample 10% of the rows in the DataFrame\n","    augment_indices = df.sample(frac=augmentation_percentage).index\n","\n","    # Apply the augment_tweet function to each tweet in the sampled rows\n","    for index in augment_indices:\n","        tweet = df.loc[index, 'text']\n","        augmented_tweet = augment_tweet(tweet)\n","        df.loc[index, 'text'] = augmented_tweet\n","    \n","    return df\n","  \n","  elif task==\"question_answering\":\n","\n","    # TODO - noise functions for QA\n","\n","    return df"],"metadata":{"id":"ohhwR8dER2NX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","random.seed(42)\n","random_noise = random.uniform(0.05, 0.15)\n","print(random_noise)\n","\n","# Download data for Testing\n","df_test = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","df_test = df_test.rename(columns={'review':'text'})\n","df_test = df_test[['text', 'sentiment']]\n","\n"," \n","# How much of the dataset to use\n","data_size = 0.2\n","df_test = df_test.sample(frac=data_size, random_state=42)\n","\n","df_test['text'] = df_test['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","df_test['sentiment'] = df_test['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = df_test[df_test['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","df_test.drop(empty_rows.index, inplace=True)\n","\n","df_test = add_noise(df_test, augmentation_percentage=random_noise, task=\"sentiment_analysis\")\n","\n","# Separate the dataset into three subsets based on the sentiment labels\n","positive_reviews = df_test[df_test['sentiment'] == sentiment_map['positive']]\n","negative_reviews = df_test[df_test['sentiment'] == sentiment_map['negative']]\n","\n","# Shuffle each of the two subsets randomly\n","positive_reviews = positive_reviews.sample(frac=1, random_state=42)\n","negative_reviews = negative_reviews.sample(frac=1, random_state=42)\n","\n","print(len(positive_reviews), len(negative_reviews))\n","# Divide each subset into training, validation, and test sets with a 70/20/10 ratio\n","train_pos, val_pos_test_pos = train_test_split(positive_reviews, test_size=0.3, random_state=42)\n","val_pos, test_pos = train_test_split(val_pos_test_pos, test_size=0.33, random_state=42)\n","\n","train_neg, val_neg_test_neg = train_test_split(negative_reviews, test_size=0.3, random_state=42)\n","val_neg, test_neg = train_test_split(val_neg_test_neg, test_size=0.33, random_state=42)\n","\n","# Merge the corresponding subsets from each sentiment back together to form the final training, validation, and test sets\n","train_set = pd.concat([train_pos, train_neg], ignore_index=True)\n","val_set = pd.concat([val_pos, val_neg], ignore_index=True)\n","test_set = pd.concat([test_pos, test_neg], ignore_index=True)\n","\n","# For test\n","\n","texts = test_set.text.values\n","labels = test_set.sentiment.values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids, dim=0)\n","attention_masks_test = torch.cat(attention_masks, dim=0)\n","labels_test = torch.tensor(labels)\n","\n","\n","test_dataset=[]\n","for i in range(num_test):\n","  test_dataset.append((input_ids_test[i], attention_masks_test[i], labels_test[i]))\n","\n","import torch\n","\n","# Specify device\n","device = torch.device('cpu')\n","\n","# Load model for evaluations, comment for finetuning\n","path = '/content/gdrive/MyDrive/NLP Project/models/# Specify device'\n","device = torch.device('cpu')\n","\n","# Load model for evaluations, comment for finetuning\n","path = '/content/gdrive/MyDrive/NLP Project/models/BERT_SA_clean100'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth'))\n","\n","model.to(device)\n","input_ids_test = input_ids_test.to(device)\n","attention_masks_test = attention_masks_test.to(device)\n","labels_test = labels_test.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids=input_ids_test, attention_mask=attention_masks_test)\n","    logits = outputs.logits\n","model.load_state_dict(torch.load(path+'/model_parameters.pth', map_location=device))\n","\n","model.to(device)\n","input_ids_test = input_ids_test.to(device)\n","attention_masks_test = attention_masks_test.to(device)\n","labels_test = labels_test.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids=input_ids_test, attention_mask=attention_masks_test)\n","    logits = outputs.logits\n","\n","# Apply softmax to obtain probabilities\n","probs = torch.softmax(logits, dim=1)\n","preds = torch.argmax(probs, dim=1)\n","\n","# Move predictions and labels back to CPU for evaluation\n","preds = preds.detach().cpu().numpy()\n","labels_test = labels_test.cpu().numpy()\n","\n","# Calculate accuracy\n","accuracy = (preds == labels_test).mean()\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n","from sklearn.metrics import f1_score\n","\n","f1 = f1_score(labels_test, preds, average='weighted')\n","print(f'F1 Score: {f1:.4f}')"],"metadata":{"id":"da1B8mu6R20t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684338844784,"user_tz":240,"elapsed":454584,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"outputId":"c46db808-c205-4358-f7fe-8c345b92069b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.11394267984578837\n","5039 4961\n","Test Accuracy: 0.7760\n","F1 Score: 0.7753\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1QcOxg4NUIHZiKRFTw8CafCVMeHURYrjP","timestamp":1683414003391},{"file_id":"1m_3Zcx57629wlNaV6OXeXdgwsMAVjeDH","timestamp":1683057305184}],"gpuType":"T4","collapsed_sections":["-b0Kh7PFMO9q","FSf542_wMTjp","r3JNeLHnNl04"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07880a5fb78144869190f7489e2daff4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_359aebc9ba8a4643aa4218abf49827ca","IPY_MODEL_01d670a7af914f4db15793ec527496c6","IPY_MODEL_128f7324eebe4e8c89c6ca53f2434f07"],"layout":"IPY_MODEL_dbefc1ebe6c746df9c672040a8a517b3"}},"359aebc9ba8a4643aa4218abf49827ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af75a7912042443f9331398da314660e","placeholder":"​","style":"IPY_MODEL_f4f7dec25e954aca8f3593f159cd70fd","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"01d670a7af914f4db15793ec527496c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63adb979f3da4c8cbeb561cf7c7f66d5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bfa04876dc7a489093f377abd7b9d601","value":231508}},"128f7324eebe4e8c89c6ca53f2434f07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a184cce7e15420dbdeddcd96d04a9eb","placeholder":"​","style":"IPY_MODEL_57e1d047c47e4f0b8de792ac4068f6fe","value":" 232k/232k [00:00&lt;00:00, 1.97MB/s]"}},"dbefc1ebe6c746df9c672040a8a517b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af75a7912042443f9331398da314660e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4f7dec25e954aca8f3593f159cd70fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63adb979f3da4c8cbeb561cf7c7f66d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfa04876dc7a489093f377abd7b9d601":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a184cce7e15420dbdeddcd96d04a9eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57e1d047c47e4f0b8de792ac4068f6fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acc7941e26c24d9c8eee3265b2726566":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4383a0e023564760876896b3848c87da","IPY_MODEL_885824d1e2444552b1dab269504201b5","IPY_MODEL_6d51b1ee6e8d48e4937cf9b6a96b7b4f"],"layout":"IPY_MODEL_bf0f955fc7ca4e8f9bd8cc7f7bbe8716"}},"4383a0e023564760876896b3848c87da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4bc847a46984b2ba652ffecb78795bb","placeholder":"​","style":"IPY_MODEL_382cccac73224227af6f11b59d77f219","value":"Downloading (…)okenizer_config.json: 100%"}},"885824d1e2444552b1dab269504201b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7d7e4ba76cf44839f1149b2af058213","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33178c34aa0443e6873a2903e195df16","value":28}},"6d51b1ee6e8d48e4937cf9b6a96b7b4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35172b7700924081bcba71821888c093","placeholder":"​","style":"IPY_MODEL_21e67b2f267146ec952a3c20c7148de3","value":" 28.0/28.0 [00:00&lt;00:00, 611B/s]"}},"bf0f955fc7ca4e8f9bd8cc7f7bbe8716":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4bc847a46984b2ba652ffecb78795bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"382cccac73224227af6f11b59d77f219":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7d7e4ba76cf44839f1149b2af058213":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33178c34aa0443e6873a2903e195df16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35172b7700924081bcba71821888c093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21e67b2f267146ec952a3c20c7148de3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a670af518414d50943798ed21e3f82d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5cb6a15f2ad439387b19ab43b9ccf85","IPY_MODEL_21e3b92dcd2748f98e607431df0c7780","IPY_MODEL_6b589e7d0eaf4363998d4344842a38db"],"layout":"IPY_MODEL_e7c742c49b7446cd8ab0c431a8954770"}},"a5cb6a15f2ad439387b19ab43b9ccf85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4997f66720fa41cf924121f036406e7e","placeholder":"​","style":"IPY_MODEL_f6397d18e1664415a39780b93842c99c","value":"Downloading (…)lve/main/config.json: 100%"}},"21e3b92dcd2748f98e607431df0c7780":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69d30fad19424e12b9d72ee4064235c4","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11fe4f655b504888b7704d568c38d389","value":570}},"6b589e7d0eaf4363998d4344842a38db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f21aa3751d314d3d941927fedef886b9","placeholder":"​","style":"IPY_MODEL_02685b7aee1c4150b83e847410d8e4ee","value":" 570/570 [00:00&lt;00:00, 12.1kB/s]"}},"e7c742c49b7446cd8ab0c431a8954770":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4997f66720fa41cf924121f036406e7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6397d18e1664415a39780b93842c99c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69d30fad19424e12b9d72ee4064235c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11fe4f655b504888b7704d568c38d389":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f21aa3751d314d3d941927fedef886b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02685b7aee1c4150b83e847410d8e4ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35f56c2801404e8ebd9898f8973a073f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5238ac4530154bc3ae0b74bdf42ee8cd","IPY_MODEL_4530cdef24ad4d06a9d43bc26b6914c4","IPY_MODEL_f28826c71fa343888eef655bd802bbe3"],"layout":"IPY_MODEL_72e2bb34daca43efb998632dc941ad01"}},"5238ac4530154bc3ae0b74bdf42ee8cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b292a6796a6243bf8f199db8a8b3cabb","placeholder":"​","style":"IPY_MODEL_17e0c38a1ca946e7ba104726677b52c2","value":"Downloading pytorch_model.bin: 100%"}},"4530cdef24ad4d06a9d43bc26b6914c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09dbedad37214a76a965d4ba7def7769","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06fc5a247b1f4094b1d9a8fd9233d1e7","value":440473133}},"f28826c71fa343888eef655bd802bbe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab79a31327b546dfbd7926d16f73dc8b","placeholder":"​","style":"IPY_MODEL_f11399b9126c4ce381f0672e65f137e5","value":" 440M/440M [00:02&lt;00:00, 230MB/s]"}},"72e2bb34daca43efb998632dc941ad01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b292a6796a6243bf8f199db8a8b3cabb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17e0c38a1ca946e7ba104726677b52c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09dbedad37214a76a965d4ba7def7769":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06fc5a247b1f4094b1d9a8fd9233d1e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab79a31327b546dfbd7926d16f73dc8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f11399b9126c4ce381f0672e65f137e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}