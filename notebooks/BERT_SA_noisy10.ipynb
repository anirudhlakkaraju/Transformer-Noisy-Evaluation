{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20197,"status":"ok","timestamp":1684295204285,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"h-t39GWCNkXO","outputId":"d58f6800-2ef1-4e8d-8727-bddba49be80a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31035,"status":"ok","timestamp":1684295238854,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"KbhyWqs0kAOq","outputId":"5cb84d6b-950a-480b-b510-2e245776384d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}],"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","!pip install sentencepiece\n","!pip install nlpaug"]},{"cell_type":"markdown","metadata":{"id":"-b0Kh7PFMO9q"},"source":["###Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFyllB4kRQct"},"outputs":[],"source":["# Import required libraries\n","import torch\n","import pandas as pd\n","import numpy as np\n","import re\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, f1_score\n","import random\n","from tqdm.auto import tqdm\n","import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684295256313,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"VJUs_qRSP9YO","outputId":"8b36871f-bbcd-488c-e071-5433e57e75fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}],"source":["\n","import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0REebhaMhbg"},"outputs":[],"source":["def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31748,"status":"ok","timestamp":1684295288056,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"sTFvVgIZQjk6","outputId":"a4bce601-229f-40f4-dc5c-3a0059dadfe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","success!\n","helper file downloaded! (helpers.py)\n"]}],"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')\n","\n","import os\n","import zipfile\n","\n","# Download helper functions file\n","helper_file = drive.CreateFile({'id': '16HW-z9Y1tM3gZ_vFpJAuwUDohz91Aac-'})\n","helper_file.GetContentFile('helpers.py')\n","print('helper file downloaded! (helpers.py)')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FSf542_wMTjp"},"source":["### Data download and preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1301,"status":"ok","timestamp":1684295289355,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"hkiufbTtM3Kr","outputId":"e353d8a6-0597-45ff-f579-658311bb3a0b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def clean_text(text):\n","    # Convert all text to lowercase\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    # Remove numbers\n","    text = re.sub(r'\\d+', '', text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = nltk.word_tokenize(text)\n","    tokens = [token for token in tokens if token not in stop_words]\n","    text = ' '.join(tokens)\n","\n","    # Remove extra whitespaces\n","    text = re.sub(' +', ' ', text)\n","\n","    return text"]},{"cell_type":"markdown","metadata":{"id":"c3iFICQrhkRn"},"source":["###Noise Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HblA7Ux8hoAK"},"outputs":[],"source":["# Noise funcs \n","\n","char_action = ['insert',\n","        'substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","word_action = ['substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","\n","def get_action(type):\n","  if type==\"char\":\n","    return random.choice(char_action)\n","  elif type==\"word\":\n","    return random.choice(word_action)\n","\n","\n","def augment_tweet(tweet, p=0.7):\n","    \"\"\"\n","    Augment a tweet with character-level and word-level noise.\n","\n","    Args:\n","        tweet (str): The original tweet.\n","        p (float): The probability of applying the char level augmentation.\n","\n","    Returns:\n","        str: The augmented tweet.\n","    \"\"\"\n","    # Define a list of character-level augmentation techniques\n","    char_augmenters = [\n","        nac.OcrAug(),\n","        nac.KeyboardAug(aug_char_p=0.2, aug_word_p=0.2, include_special_char=False),\n","        nac.RandomCharAug(action=get_action(\"char\"), aug_char_p=0.1, aug_word_p=0.1),\n","    ]\n","\n","    # Define a list of word-level augmentation techniques\n","    word_augmenters = [\n","        naw.SpellingAug(),\n","        naw.SplitAug(),\n","        naw.SynonymAug(),\n","        naw.RandomWordAug(aug_p=0.2, action=get_action(\"word\")),\n","    ]\n","\n","    # Randomly apply a character-level or word-level augmentation with probability p\n","    if random.random() < p:\n","        aug = random.choice(char_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","    else:\n","        aug = random.choice(word_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","        \n","    return augmented_tweet\n","\n","def add_noise(df, augmentation_percentage, task):\n","\n","  if task==\"sentiment_analysis\":\n","    # Sample 10% of the rows in the DataFrame\n","    augment_indices = df.sample(frac=augmentation_percentage).index\n","\n","    # Apply the augment_tweet function to each tweet in the sampled rows\n","    for index in augment_indices:\n","        tweet = df.loc[index, 'text']\n","        augmented_tweet = augment_tweet(tweet)\n","        df.loc[index, 'text'] = augmented_tweet\n","    \n","    return df\n","  \n","  elif task==\"question_answering\":\n","\n","    #noise functions for QA\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-FypXfWQ0iN"},"outputs":[],"source":["from helpers import tokenize_and_format, flat_accuracy\n","\n","df = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","df = df.rename(columns={'review':'text'})\n","df = df[['text', 'sentiment']]\n","\n","# How much of the dataset to use\n","data_size = 0.2\n","df = df.sample(frac=data_size, random_state=42)\n","\n","df['text'] = df['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","df['sentiment'] = df['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = df[df['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","df.drop(empty_rows.index, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11998,"status":"ok","timestamp":1684295333681,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"vcDdta71huOR","outputId":"923efa27-9e7c-4b66-fd92-022a8982a063"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}],"source":["#Adding noise of 10%\n","# Add word and char level noise 10%\n","df = add_noise(df, augmentation_percentage=0.1, task=\"sentiment_analysis\")\n","\n","# Randomly shuffle all rows\n","df = df.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"r3JNeLHnNl04"},"source":["### Train/val/test splits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxjCvi_Ids5O"},"outputs":[],"source":["# Separate the dataset into three subsets based on the sentiment labels\n","positive_reviews = df[df['sentiment'] == sentiment_map['positive']]\n","negative_reviews = df[df['sentiment'] == sentiment_map['negative']]\n","\n","# Shuffle each of the two subsets randomly\n","positive_reviews = positive_reviews.sample(frac=1, random_state=42)\n","negative_reviews = negative_reviews.sample(frac=1, random_state=42)\n","\n","# Divide each subset into training, validation, and test sets with a 70/20/10 ratio\n","train_pos, val_pos_test_pos = train_test_split(positive_reviews, test_size=0.3, random_state=42)\n","val_pos, test_pos = train_test_split(val_pos_test_pos, test_size=0.33, random_state=42)\n","\n","train_neg, val_neg_test_neg = train_test_split(negative_reviews, test_size=0.3, random_state=42)\n","val_neg, test_neg = train_test_split(val_neg_test_neg, test_size=0.33, random_state=42)\n","\n","# Merge the corresponding subsets from each sentiment back together to form the final training, validation, and test sets\n","train_set = pd.concat([train_pos, train_neg], ignore_index=True)\n","val_set = pd.concat([val_pos, val_neg], ignore_index=True)\n","test_set = pd.concat([test_pos, test_neg], ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["bb405027fd5e436c86446c8ac74964f1","df9abd736175416fb39879ea8e7ccbe2","8565ce3103134c09916022ebb6f1f202","0aa7635f5ecc4fe48ca1ec6ce0005eb8","f96aa2b4380547ca92d679c9cbfff85b","5cfdafe353014322a2e7bc819fae0422","9cc71306a3084c2da51ac3c48dc7834a","025e32d1e8f84619a612c6ce407cc5d7","3c5f3c0d1d5d44acbe3d62a4322160f1","2a0cd07ec87e4374ae407d20137ed3f0","f8099420fd61432d876028b704aea83b","b2806efdcafd4562af58de825123dcf2","f33e84ddfe264057bf316c0dfd7e72b1","002e502eea5e4db5b9130a1a9b4a8aec","a2c52d8b9c144909bacc0d0f7c7e2601","70e1db83aecf40ae96f2c859eff56080","d4a0d0b3409a41bc8cd1ecb86fd7224d","6613927f5b94489ea6f2d8427718f225","20d57bdba0a4464bac3d0dd2e993f0c3","21bcdcb7e8a748ea89c33d83a1907d02","97c8cd717fb24edea17e3b7d6bdaf623","5e346a05bb18455ab7633f0ba73acf0d","fe7e97d84e0d4c6face6f171dac6c853","70ec48a681644efba148e998f3c7ac0b","f9603d7493c442abb4c776b9bc98fb66","fc19655a85194c82956275cdcc679ef0","2d853736b49b41cba7a508f232ec44c6","07e84913714d421eaf6613801fe541ea","3f969d1e1fee4c038261d115e331c3f5","a7315b6c59934007bfa509ab9d5aab70","39a8cd3de4b64f228b18ba447503e444","c2a2f9a44a304b47ad1b648535790e3b","859e69a77e2742edbbc3b879e72332d0"]},"executionInfo":{"elapsed":20676,"status":"ok","timestamp":1684295354343,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"w59g7FkaSiLU","outputId":"35624a40-bdcb-4590-8ef2-0388a6b3db22"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb405027fd5e436c86446c8ac74964f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2806efdcafd4562af58de825123dcf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe7e97d84e0d4c6face6f171dac6c853"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original:  movies loved almost everyone come across yet happen boxoffice failures andaz apna apna intelligent hilarious comedy falls catogory indian director kept mind sensibilities audience churned kader khan type stereotypical hoax movie two guys dream riches try accomplish wooing millionaires daughter humorous drama unfolds lot complexities surface story complexities add sheer comedy entire plot aamir khan plays streetsmart guy salman khan gives unexpectedly good performance dumb guy villian played paresh rawaland henchmen junior ajit kaliaa make laugh sleep although movie borrows lot movies despite shoddy camerawork despite loud times remains one scarce funny movies bombay come movies like padosan golmal amol plaekar movies sad didnt well boxoffice means producers turn back formulas creativity abandoned\n","Token IDs: tensor([[  101,  5691,  3866,  2471,  3071,  2272,  2408,  2664,  4148,  3482,\n","          7245,  6610, 15428,  1998, 10936,  9706,  2532,  9706,  2532,  9414,\n","         26316,  4038,  4212,  4937, 22844,  2854,  2796,  2472,  2921,  2568,\n","         12411,  5332, 14680,  4378, 14684, 21119, 26159,  2099,  4967,  2828,\n","         12991, 27086, 28520,  3185,  2048,  4364,  3959, 26768,  3046, 14570,\n","         15854,  2075, 19965,  2015,  2684, 14742,  3689,  4895, 10371,  2015,\n","          2843,  3375,  6447,   102]])\n"]}],"source":["# tokenize train, test and val individually\n","# For train\n","\n","texts = train_set.text.values\n","labels = train_set.sentiment.values\n","\n","# tokenize_and_format() is a helper function provided in helpers.py\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_train = torch.cat(input_ids, dim=0)\n","attention_masks_train = torch.cat(attention_masks, dim=0)\n","labels_train = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4885,"status":"ok","timestamp":1684295359210,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"G-u5LOvBTcs5","outputId":"6c2dbf75-1270-4f24-b640-1ca189ff0bc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  actually good surreal mystery movie despite description tries sell scifi movie balkan stars woman haunted mysterious visions lost memories trying piece together spends majority movie trying make sense visions atmospheric effective true kinski appear much film staring actors good english dubbed version available us dubbing leaves something desired actors good job cinematography academy award winner vittorio storaro excellent earlier giallo director bazzoni fifth cord also excellent also lensed storarro\n","Token IDs: tensor([[  101,  2941,  2204, 16524,  6547,  3185,  2750,  6412,  5363,  5271,\n","         16596,  8873,  3185, 17581,  3340,  2450, 11171,  8075, 12018,  2439,\n","          5758,  2667,  3538,  2362, 15970,  3484,  3185,  2667,  2191,  3168,\n","         12018, 12483,  4621,  2995, 12631,  5488,  3711,  2172,  2143,  4582,\n","          5889,  2204,  2394,  9188,  2544,  2800,  2149, 12931, 10472,  3727,\n","          2242,  9059,  5889,  2204,  3105, 16434,  2914,  2400,  3453, 25914,\n","          2358,  6525,  3217,   102]])\n"]}],"source":["# For test\n","texts = test_set.text.values\n","labels = test_set.sentiment.values\n","\n","# tokenize_and_format() is a helper function provided in helpers.py\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids, dim=0)\n","attention_masks_test = torch.cat(attention_masks, dim=0)\n","labels_test = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4834,"status":"ok","timestamp":1684295364028,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"XQDvnkEBTpV9","outputId":"c1f3ebf6-62a6-4db4-b752-eb1a87f66a74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  far best war documentary ever made beginning first episode sir laurence olivier described horrific events oradoursurglane day soldiers came final days war mushroom clouds appeared japan never missed second classic series remember well even though screened way back every aspect tragedy covered detail whole series compulsory viewing many worlds children possible tragedy world war two repeated bigotry hatred greed intolerance confused patriotism religious zeal\n","Token IDs: tensor([[  101,  2521,  2190,  2162,  4516,  2412,  2081,  2927,  2034,  2792,\n","          2909, 10883, 14439,  2649, 23512,  2824,  2030,  9365,  9236, 12514,\n","         20644,  2154,  3548,  2234,  2345,  2420,  2162, 18565,  8044,  2596,\n","          2900,  2196,  4771,  2117,  4438,  2186,  3342,  2092,  2130,  2295,\n","         12238,  2126,  2067,  2296,  7814, 10576,  3139,  6987,  2878,  2186,\n","         14770, 10523,  2116,  8484,  2336,  2825, 10576,  2088,  2162,  2048,\n","          5567,  2502,  4140,   102]])\n"]}],"source":["# For val\n","texts = val_set.text.values\n","labels = val_set.sentiment.values\n","\n","# tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_val = torch.cat(input_ids, dim=0)\n","attention_masks_val = torch.cat(attention_masks, dim=0)\n","labels_val = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684295364028,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"wyYzcjXzT7e9","outputId":"669a5686-cb31-42bd-f146-804a8d84b0ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Set Size:  6999\n","Validation Set Size:  2010\n","Test Set Size:  991\n"]}],"source":["#printing out len of train,test val\n","total = len(df)\n","num_train = len(train_set)\n","num_val = len(val_set)\n","num_test = len(test_set)\n","\n","print('Train Set Size: ',num_train)\n","print('Validation Set Size: ',num_val)\n","print('Test Set Size: ',num_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDKpkqDyXwg4"},"outputs":[],"source":["# make lists of 3-tuples \n","train_dataset=[]\n","for i in range(num_train):\n","  train_dataset.append((input_ids_train[i], attention_masks_train[i], labels_train[i]))\n","\n","val_dataset=[]\n","for i in range(num_val):\n","  val_dataset.append((input_ids_val[i], attention_masks_val[i], labels_val[i]))\n","\n","test_dataset=[]\n","for i in range(num_test):\n","  test_dataset.append((input_ids_test[i], attention_masks_test[i], labels_test[i]))\n"]},{"cell_type":"markdown","metadata":{"id":"hpzmG9IMOEQm"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["4841e54b7d5d4b8283a95f896d8d106c","623504dd401f42309fab7c2a3ca00194","88df6167942e4f1fbd221b92b3fa5359","a5599dbbc65b485985a0a4d55de87c0b","73769fa616ea49d99bab083df159da76","0b84129e1e924bc690a100e8c7d02f4a","8c02ec6e5fed418aa0ad67ecab5b2ec3","4239a6efd47240e2a746a0745d31e32d","c01526d724e34798bf1dacd919140d48","1ca5d24a3eff4de2832eb8169f56044c","881d54197e884c8a84689a47841ac24c"]},"executionInfo":{"elapsed":15938,"status":"ok","timestamp":1684295380430,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"dSu09pqLTEZo","outputId":"ef6fad9b-4285-4b56-96b7-5e07f091aa36"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4841e54b7d5d4b8283a95f896d8d106c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Define the BERT model for sequence classification\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()\n","\n","# Set the optimizer and learning rate scheduler\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","total_steps = len(train_dataset) * 4\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1684295380430,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"2OxQEBsQXfko","outputId":"2b521f7b-2d8a-4699-c7bf-22c37138c6a7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Define the training loop\\nmodel.to(device)\\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\\nbest_val_loss = float(\"inf\")\\nnum_epochs = 2\\ntrain_loss = []\\nval_loss = []\\nfor epoch in range(num_epochs):\\n  # Train the model\\n  model.train()\\n  epoch_loss = 0\\n\\n  train_loop = tqdm(train_loader, desc=f\\'Training Epoch {epoch+1}\\', leave=True)\\n\\n  for batch in train_loop:\\n      \\n    inputs = {\\'input_ids\\': batch[0].to(device),\\n              \\'attention_mask\\': batch[1].to(device),\\n              \\'labels\\': batch[2].to(device)}\\n    optimizer.zero_grad()\\n    outputs = model(**inputs)\\n    loss = outputs[0]\\n\\n    loss.backward()\\n    optimizer.step()\\n    scheduler.step()\\n\\n    epoch_loss += loss.item()\\n    train_loop.set_postfix(loss=loss.item())\\n\\n  epoch_loss /= len(train_loader)\\n  train_loss.append(epoch_loss)\\n\\n  # Evaluate the model on the validation set\\n  model.eval()\\n  val_preds = []\\n  val_labels = []\\n  epoch_val_loss = 0\\n\\n  with torch.no_grad():\\n    for batch in val_loader:\\n        \\n      inputs = {\\'input_ids\\': batch[0].to(device),\\n                \\'attention_mask\\': batch[1].to(device),\\n                \\'labels\\': batch[2].to(device)}\\n      \\n      outputs = model(**inputs)\\n      loss = outputs[0]\\n      epoch_val_loss += loss.item()\\n\\n      logits = outputs[1]\\n      preds = torch.argmax(logits, axis=1)\\n      val_preds.extend(preds.cpu().numpy())\\n      val_labels.extend(batch[2].cpu().numpy())\\n\\n    epoch_val_loss /= len(val_loader)\\n\\n  if epoch_val_loss < best_val_loss:\\n    best_val_loss = epoch_val_loss\\n    # torch.save(model.state_dict(), \"t5_sentiment_model.pt\")\\n    path = \\'/content/gdrive/MyDrive/NLP Project/models/BERT_SA_noisy10_100\\'\\n\\n    torch.save(model.state_dict(), path+\\'/model_parameters.pth\\')\\n\\n  # Compute the evaluation metrics\\n  val_accuracy = accuracy_score(val_labels, val_preds)\\n  val_report = classification_report(val_labels, val_preds, target_names=[\\'positive\\', \\'negative\\'])\\n  \\n\\n  # Print the results for the current epoch\\n  print(\\'Epoch:\\', epoch+1, \\', Training Loss:\\', epoch_loss/len(train_loader), \\', Validation Loss:\\', epoch_val_loss, \\', Validation Accuracy:\\', val_accuracy)\\n  print(\\'Validation Classification Report:\\')\\n  print(val_report)\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["'''# Define the training loop\n","model.to(device)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n","best_val_loss = float(\"inf\")\n","num_epochs = 2\n","train_loss = []\n","val_loss = []\n","for epoch in range(num_epochs):\n","  # Train the model\n","  model.train()\n","  epoch_loss = 0\n","\n","  train_loop = tqdm(train_loader, desc=f'Training Epoch {epoch+1}', leave=True)\n","\n","  for batch in train_loop:\n","      \n","    inputs = {'input_ids': batch[0].to(device),\n","              'attention_mask': batch[1].to(device),\n","              'labels': batch[2].to(device)}\n","    optimizer.zero_grad()\n","    outputs = model(**inputs)\n","    loss = outputs[0]\n","\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    epoch_loss += loss.item()\n","    train_loop.set_postfix(loss=loss.item())\n","\n","  epoch_loss /= len(train_loader)\n","  train_loss.append(epoch_loss)\n","\n","  # Evaluate the model on the validation set\n","  model.eval()\n","  val_preds = []\n","  val_labels = []\n","  epoch_val_loss = 0\n","\n","  with torch.no_grad():\n","    for batch in val_loader:\n","        \n","      inputs = {'input_ids': batch[0].to(device),\n","                'attention_mask': batch[1].to(device),\n","                'labels': batch[2].to(device)}\n","      \n","      outputs = model(**inputs)\n","      loss = outputs[0]\n","      epoch_val_loss += loss.item()\n","\n","      logits = outputs[1]\n","      preds = torch.argmax(logits, axis=1)\n","      val_preds.extend(preds.cpu().numpy())\n","      val_labels.extend(batch[2].cpu().numpy())\n","\n","    epoch_val_loss /= len(val_loader)\n","\n","  if epoch_val_loss < best_val_loss:\n","    best_val_loss = epoch_val_loss\n","    # torch.save(model.state_dict(), \"t5_sentiment_model.pt\")\n","    path = '/content/gdrive/MyDrive/NLP Project/models/BERT_SA_noisy10_100'\n","\n","    torch.save(model.state_dict(), path+'/model_parameters.pth')\n","\n","  # Compute the evaluation metrics\n","  val_accuracy = accuracy_score(val_labels, val_preds)\n","  val_report = classification_report(val_labels, val_preds, target_names=['positive', 'negative'])\n","  \n","\n","  # Print the results for the current epoch\n","  print('Epoch:', epoch+1, ', Training Loss:', epoch_loss/len(train_loader), ', Validation Loss:', epoch_val_loss, ', Validation Accuracy:', val_accuracy)\n","  print('Validation Classification Report:')\n","  print(val_report)\n","    '''"]},{"cell_type":"markdown","metadata":{"id":"BRZG8cVSi3VL"},"source":["###Evaluation on Clean Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Wk98e0rJ7TX"},"outputs":[],"source":["from helpers import tokenize_and_format, flat_accuracy\n","\n","test_df = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","test_df = test_df.rename(columns={'review':'text'})\n","test_df = test_df[['text', 'sentiment']]\n","\n","# How much of the dataset to use\n","data_size = 0.2\n","test_df = test_df.sample(frac=data_size, random_state=42)\n","\n","test_df['text'] = test_df['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","test_df['sentiment'] = test_df['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = test_df[test_df['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","test_df.drop(empty_rows.index, inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hq0MXeaCQs8t"},"outputs":[],"source":["# Separate the dataset into three subsets based on the sentiment labels\n","positive_reviews = test_df[test_df['sentiment'] == sentiment_map['positive']]\n","negative_reviews = test_df[test_df['sentiment'] == sentiment_map['negative']]\n","\n","# Shuffle each of the two subsets randomly\n","positive_reviews = positive_reviews.sample(frac=1, random_state=42)\n","negative_reviews = negative_reviews.sample(frac=1, random_state=42)\n","\n","# Divide each subset into training, validation, and test sets with a 70/20/10 ratio\n","train_pos, val_pos_test_pos = train_test_split(positive_reviews, test_size=0.3, random_state=42)\n","val_pos, test_pos = train_test_split(val_pos_test_pos, test_size=0.33, random_state=42)\n","\n","train_neg, val_neg_test_neg = train_test_split(negative_reviews, test_size=0.3, random_state=42)\n","val_neg, test_neg = train_test_split(val_neg_test_neg, test_size=0.33, random_state=42)\n","\n","# Merge the corresponding subsets from each sentiment back together to form the final training, validation, and test sets\n","train_set = pd.concat([train_pos, train_neg], ignore_index=True)\n","val_set = pd.concat([val_pos, val_neg], ignore_index=True)\n","test_set = pd.concat([test_pos, test_neg], ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4671,"status":"ok","timestamp":1684259226193,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"GUvyEJyQOnDf","outputId":"236e2025-a600-436f-f2f4-d8ffaad22360"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  one movies dont require brain thinking funny time pass forgot next hour really surprised john abrahams acting usually playing gangster like character emotionless faceso playing complete opposite successfullyby managing shine amongst comic geniuses paresh rawal akshaye kumar also quite surprised akshayes girls roles dont require much talent mostly moaning akshayes dissapearenceto girls surprised managed establish actual persona could differentiate good thing also majority songs goodit colourful fun boring sunday evening sure lighten mood\n","Token IDs: tensor([[  101,  2028,  5691,  2123,  2102,  5478,  4167,  3241,  6057,  2051,\n","          3413,  9471,  2279,  3178,  2428,  4527,  2198,  8181,  2015,  3772,\n","          2788,  2652, 20067,  2066,  2839,  7603,  3238,  5344,  2080,  2652,\n","          3143,  4500,  5147,  3762,  6605, 12342,  5921,  5021, 11067,  2229,\n","         11968,  9953,  6315,  2389, 17712,  7377,  6672,  9600,  2036,  3243,\n","          4527, 17712,  7377, 23147,  3057,  4395,  2123,  2102,  5478,  2172,\n","          5848,  3262, 22653,   102]])\n"]}],"source":["# For test\n","texts = test_set.text.values\n","labels = test_set.sentiment.values\n","\n","# tokenize_and_format() is a helper function provided in helpers.py\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids, dim=0)\n","attention_masks_test = torch.cat(attention_masks, dim=0)\n","\n","labels_test = torch.tensor(labels)\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfxpWLY5i2I1","outputId":"2b59cc87-e6ae-4a19-c6fe-2f21b3f5039d","executionInfo":{"status":"ok","timestamp":1684259233315,"user_tz":240,"elapsed":7126,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"source":["#Load model for evaluations, comment for finetuning\n","\n","path = '/content/gdrive/MyDrive/NLP Project/models/BERT_SA_noisy10_100'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZcPJWMs-ekqj","outputId":"6f405b94-d2af-477a-c67c-fb25f4457df8","executionInfo":{"status":"ok","timestamp":1684259239874,"user_tz":240,"elapsed":6573,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.9112\n","F1 Score: 0.9112\n"]}],"source":["# Move input tensors to the same device as the model\n","input_ids_test = input_ids_test.to(device)\n","attention_masks_test = attention_masks_test.to(device)\n","labels_test = labels_test.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids=input_ids_test, attention_mask=attention_masks_test)\n","    logits = outputs.logits\n","\n","# Apply softmax to obtain probabilities\n","probs = torch.softmax(logits, dim=1)\n","preds = torch.argmax(probs, dim=1)\n","\n","# Move predictions and labels back to CPU for evaluation\n","preds = preds.detach().cpu().numpy()\n","labels_test = labels_test.cpu().numpy()\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(labels_test, preds)\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n","# Calculate F1 score\n","f1 = f1_score(labels_test, preds, average='weighted')\n","print(f'F1 Score: {f1:.4f}')\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cu79r8pdRo76"},"source":["### Evaluation on Noisy Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"da1B8mu6R20t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684259396911,"user_tz":240,"elapsed":157051,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"outputId":"65389a0c-ed15-4372-d0aa-eaf9e36b1d7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.11394267984578837\n","5039 4961\n","Test Accuracy: 0.8698\n","F1 Score: 0.8694\n"]}],"source":["import random\n","random.seed(42)\n","random_noise = random.uniform(0.05, 0.15)\n","print(random_noise)\n","\n","# Download data for Testing\n","df_test = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","df_test = df_test.rename(columns={'review':'text'})\n","df_test = df_test[['text', 'sentiment']]\n","\n"," \n","# How much of the dataset to use\n","data_size = 0.2\n","df_test = df_test.sample(frac=data_size, random_state=42)\n","\n","df_test['text'] = df_test['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","df_test['sentiment'] = df_test['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = df_test[df_test['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","df_test.drop(empty_rows.index, inplace=True)\n","\n","df_test = add_noise(df_test, augmentation_percentage=random_noise, task=\"sentiment_analysis\")\n","\n","# Separate the dataset into three subsets based on the sentiment labels\n","positive_reviews = df_test[df_test['sentiment'] == sentiment_map['positive']]\n","negative_reviews = df_test[df_test['sentiment'] == sentiment_map['negative']]\n","\n","# Shuffle each of the two subsets randomly\n","positive_reviews = positive_reviews.sample(frac=1, random_state=42)\n","negative_reviews = negative_reviews.sample(frac=1, random_state=42)\n","\n","print(len(positive_reviews), len(negative_reviews))\n","# Divide each subset into training, validation, and test sets with a 70/20/10 ratio\n","train_pos, val_pos_test_pos = train_test_split(positive_reviews, test_size=0.3, random_state=42)\n","val_pos, test_pos = train_test_split(val_pos_test_pos, test_size=0.33, random_state=42)\n","\n","train_neg, val_neg_test_neg = train_test_split(negative_reviews, test_size=0.3, random_state=42)\n","val_neg, test_neg = train_test_split(val_neg_test_neg, test_size=0.33, random_state=42)\n","\n","# Merge the corresponding subsets from each sentiment back together to form the final training, validation, and test sets\n","train_set = pd.concat([train_pos, train_neg], ignore_index=True)\n","val_set = pd.concat([val_pos, val_neg], ignore_index=True)\n","test_set = pd.concat([test_pos, test_neg], ignore_index=True)\n","\n","# For test\n","\n","texts = test_set.text.values\n","labels = test_set.sentiment.values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids, dim=0)\n","attention_masks_test = torch.cat(attention_masks, dim=0)\n","labels_test = torch.tensor(labels)\n","\n","\n","test_dataset=[]\n","for i in range(num_test):\n","  test_dataset.append((input_ids_test[i], attention_masks_test[i], labels_test[i]))\n","\n","import torch\n","\n","# Specify device\n","device = torch.device('cpu')\n","\n","# Load model for evaluations, comment for finetuning\n","path = '/content/gdrive/MyDrive/NLP Project/models/BERT_SA_noisy10_100'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth', map_location=device))\n","\n","model.to(device)\n","input_ids_test = input_ids_test.to(device)\n","attention_masks_test = attention_masks_test.to(device)\n","labels_test = labels_test.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids=input_ids_test, attention_mask=attention_masks_test)\n","    logits = outputs.logits\n","\n","# Apply softmax to obtain probabilities\n","probs = torch.softmax(logits, dim=1)\n","preds = torch.argmax(probs, dim=1)\n","\n","# Move predictions and labels back to CPU for evaluation\n","preds = preds.detach().cpu().numpy()\n","labels_test = labels_test.cpu().numpy()\n","\n","# Calculate accuracy\n","accuracy = (preds == labels_test).mean()\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n","from sklearn.metrics import f1_score\n","\n","f1 = f1_score(labels_test, preds, average='weighted')\n","print(f'F1 Score: {f1:.4f}')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1D9h1hvZHcTByfSuiUrSQ6gD_2TI9SEaR","timestamp":1683937677304},{"file_id":"1QcOxg4NUIHZiKRFTw8CafCVMeHURYrjP","timestamp":1683414003391},{"file_id":"1m_3Zcx57629wlNaV6OXeXdgwsMAVjeDH","timestamp":1683057305184}],"collapsed_sections":["r3JNeLHnNl04","hpzmG9IMOEQm"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bb405027fd5e436c86446c8ac74964f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df9abd736175416fb39879ea8e7ccbe2","IPY_MODEL_8565ce3103134c09916022ebb6f1f202","IPY_MODEL_0aa7635f5ecc4fe48ca1ec6ce0005eb8"],"layout":"IPY_MODEL_f96aa2b4380547ca92d679c9cbfff85b"}},"df9abd736175416fb39879ea8e7ccbe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cfdafe353014322a2e7bc819fae0422","placeholder":"​","style":"IPY_MODEL_9cc71306a3084c2da51ac3c48dc7834a","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"8565ce3103134c09916022ebb6f1f202":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_025e32d1e8f84619a612c6ce407cc5d7","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c5f3c0d1d5d44acbe3d62a4322160f1","value":231508}},"0aa7635f5ecc4fe48ca1ec6ce0005eb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a0cd07ec87e4374ae407d20137ed3f0","placeholder":"​","style":"IPY_MODEL_f8099420fd61432d876028b704aea83b","value":" 232k/232k [00:00&lt;00:00, 3.91MB/s]"}},"f96aa2b4380547ca92d679c9cbfff85b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cfdafe353014322a2e7bc819fae0422":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cc71306a3084c2da51ac3c48dc7834a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"025e32d1e8f84619a612c6ce407cc5d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c5f3c0d1d5d44acbe3d62a4322160f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a0cd07ec87e4374ae407d20137ed3f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8099420fd61432d876028b704aea83b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2806efdcafd4562af58de825123dcf2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f33e84ddfe264057bf316c0dfd7e72b1","IPY_MODEL_002e502eea5e4db5b9130a1a9b4a8aec","IPY_MODEL_a2c52d8b9c144909bacc0d0f7c7e2601"],"layout":"IPY_MODEL_70e1db83aecf40ae96f2c859eff56080"}},"f33e84ddfe264057bf316c0dfd7e72b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4a0d0b3409a41bc8cd1ecb86fd7224d","placeholder":"​","style":"IPY_MODEL_6613927f5b94489ea6f2d8427718f225","value":"Downloading (…)okenizer_config.json: 100%"}},"002e502eea5e4db5b9130a1a9b4a8aec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20d57bdba0a4464bac3d0dd2e993f0c3","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21bcdcb7e8a748ea89c33d83a1907d02","value":28}},"a2c52d8b9c144909bacc0d0f7c7e2601":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97c8cd717fb24edea17e3b7d6bdaf623","placeholder":"​","style":"IPY_MODEL_5e346a05bb18455ab7633f0ba73acf0d","value":" 28.0/28.0 [00:00&lt;00:00, 715B/s]"}},"70e1db83aecf40ae96f2c859eff56080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a0d0b3409a41bc8cd1ecb86fd7224d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6613927f5b94489ea6f2d8427718f225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20d57bdba0a4464bac3d0dd2e993f0c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21bcdcb7e8a748ea89c33d83a1907d02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97c8cd717fb24edea17e3b7d6bdaf623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e346a05bb18455ab7633f0ba73acf0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe7e97d84e0d4c6face6f171dac6c853":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70ec48a681644efba148e998f3c7ac0b","IPY_MODEL_f9603d7493c442abb4c776b9bc98fb66","IPY_MODEL_fc19655a85194c82956275cdcc679ef0"],"layout":"IPY_MODEL_2d853736b49b41cba7a508f232ec44c6"}},"70ec48a681644efba148e998f3c7ac0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07e84913714d421eaf6613801fe541ea","placeholder":"​","style":"IPY_MODEL_3f969d1e1fee4c038261d115e331c3f5","value":"Downloading (…)lve/main/config.json: 100%"}},"f9603d7493c442abb4c776b9bc98fb66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7315b6c59934007bfa509ab9d5aab70","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39a8cd3de4b64f228b18ba447503e444","value":570}},"fc19655a85194c82956275cdcc679ef0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2a2f9a44a304b47ad1b648535790e3b","placeholder":"​","style":"IPY_MODEL_859e69a77e2742edbbc3b879e72332d0","value":" 570/570 [00:00&lt;00:00, 25.0kB/s]"}},"2d853736b49b41cba7a508f232ec44c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07e84913714d421eaf6613801fe541ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f969d1e1fee4c038261d115e331c3f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7315b6c59934007bfa509ab9d5aab70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39a8cd3de4b64f228b18ba447503e444":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2a2f9a44a304b47ad1b648535790e3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"859e69a77e2742edbbc3b879e72332d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4841e54b7d5d4b8283a95f896d8d106c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_623504dd401f42309fab7c2a3ca00194","IPY_MODEL_88df6167942e4f1fbd221b92b3fa5359","IPY_MODEL_a5599dbbc65b485985a0a4d55de87c0b"],"layout":"IPY_MODEL_73769fa616ea49d99bab083df159da76"}},"623504dd401f42309fab7c2a3ca00194":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b84129e1e924bc690a100e8c7d02f4a","placeholder":"​","style":"IPY_MODEL_8c02ec6e5fed418aa0ad67ecab5b2ec3","value":"Downloading pytorch_model.bin: 100%"}},"88df6167942e4f1fbd221b92b3fa5359":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4239a6efd47240e2a746a0745d31e32d","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c01526d724e34798bf1dacd919140d48","value":440473133}},"a5599dbbc65b485985a0a4d55de87c0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ca5d24a3eff4de2832eb8169f56044c","placeholder":"​","style":"IPY_MODEL_881d54197e884c8a84689a47841ac24c","value":" 440M/440M [00:07&lt;00:00, 56.3MB/s]"}},"73769fa616ea49d99bab083df159da76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b84129e1e924bc690a100e8c7d02f4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c02ec6e5fed418aa0ad67ecab5b2ec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4239a6efd47240e2a746a0745d31e32d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c01526d724e34798bf1dacd919140d48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ca5d24a3eff4de2832eb8169f56044c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"881d54197e884c8a84689a47841ac24c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}