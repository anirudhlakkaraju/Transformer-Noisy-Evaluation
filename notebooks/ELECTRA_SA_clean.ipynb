{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15082,"status":"ok","timestamp":1684273355021,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"h-t39GWCNkXO","outputId":"0f64a375-63db-4ac7-f5a6-2e3826e9cdc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21625,"status":"ok","timestamp":1684273391081,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"KbhyWqs0kAOq","outputId":"5f7c44ef-a079-46f2-e6b3-1f6ab6a305db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}],"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","!pip install nlpaug"]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"khndlg-Bfz6w"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"WFyllB4kRQct","executionInfo":{"status":"ok","timestamp":1684273425719,"user_tz":240,"elapsed":15721,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[],"source":["# Import required libraries\n","import torch\n","import pandas as pd\n","import numpy as np\n","import re\n","import random\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, RobertaTokenizer, RobertaForSequenceClassification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw\n","import random"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684273425719,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"VJUs_qRSP9YO","outputId":"f46b3df5-5af0-404c-dfdf-16e63bfb6a52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}],"source":["import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","source":["def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)"],"metadata":{"id":"DUekfVO6gEiL","executionInfo":{"status":"ok","timestamp":1684273425720,"user_tz":240,"elapsed":5,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Data download and preprocessing"],"metadata":{"id":"O0f2HfO2goZp"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"g306skf-RHQ_","executionInfo":{"status":"ok","timestamp":1684273426095,"user_tz":240,"elapsed":380,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"161f98b9-6f94-4d0a-a815-05f59c738a0b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def clean_text(text):\n","    # Convert all text to lowercase\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    # Remove numbers\n","    text = re.sub(r'\\d+', '', text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = nltk.word_tokenize(text)\n","    tokens = [token for token in tokens if token not in stop_words]\n","    text = ' '.join(tokens)\n","\n","    # Remove extra whitespaces\n","    text = re.sub(' +', ' ', text)\n","\n","    return text"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"B-FypXfWQ0iN","executionInfo":{"status":"ok","timestamp":1684273447908,"user_tz":240,"elapsed":16248,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[],"source":["df = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","df = df.rename(columns={'review':'text'})\n","df = df[['text', 'sentiment']]\n","\n"," \n","# How much of the dataset to use\n","data_size = 0.2\n","df = df.sample(frac=data_size, random_state=42)\n","\n","df['text'] = df['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","df['sentiment'] = df['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = df[df['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","df.drop(empty_rows.index, inplace=True)"]},{"cell_type":"markdown","source":["### Train/val/test splits"],"metadata":{"id":"Hk-bKO5jg49g"}},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684273447908,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"IptKJwtwRkrw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f0487606-f747-4450-c9ee-b962abf8a5a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["5039 4961\n"]}],"source":["# Separate the dataset into three subsets based on the sentiment labels\n","positive_reviews = df[df['sentiment'] == sentiment_map['positive']]\n","negative_reviews = df[df['sentiment'] == sentiment_map['negative']]\n","\n","# Shuffle each of the two subsets randomly\n","positive_reviews = positive_reviews.sample(frac=1, random_state=42)\n","negative_reviews = negative_reviews.sample(frac=1, random_state=42)\n","\n","print(len(positive_reviews), len(negative_reviews))\n","# Divide each subset into training, validation, and test sets with a 70/20/10 ratio\n","train_pos, val_pos_test_pos = train_test_split(positive_reviews, test_size=0.3, random_state=42)\n","val_pos, test_pos = train_test_split(val_pos_test_pos, test_size=0.33, random_state=42)\n","\n","train_neg, val_neg_test_neg = train_test_split(negative_reviews, test_size=0.3, random_state=42)\n","val_neg, test_neg = train_test_split(val_neg_test_neg, test_size=0.33, random_state=42)\n","\n","# Merge the corresponding subsets from each sentiment back together to form the final training, validation, and test sets\n","train_set = pd.concat([train_pos, train_neg], ignore_index=True)\n","val_set = pd.concat([val_pos, val_neg], ignore_index=True)\n","test_set = pd.concat([test_pos, test_neg], ignore_index=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"sTFvVgIZQjk6","executionInfo":{"status":"ok","timestamp":1684273447908,"user_tz":240,"elapsed":2,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[],"source":["from transformers import ElectraTokenizer\n","\n","def tokenize_and_format(sentences):\n","  tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n","\n","  # Tokenize all of the sentences and map the tokens to thier word IDs.\n","  input_ids = []\n","  attention_masks = []\n","\n","  # For every sentence...\n","  for sentence in sentences:\n","      # `encode_plus` will:\n","      #   (1) Tokenize the sentence.\n","      #   (2) Prepend the `[CLS]` token to the start.\n","      #   (3) Append the `[SEP]` token to the end.\n","      #   (4) Map tokens to their IDs.\n","      #   (5) Pad or truncate the sentence to `max_length`\n","      #   (6) Create attention masks for [PAD] tokens.\n","      encoded_dict = tokenizer.encode_plus(\n","                          sentence,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 64,           # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation = True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","\n","      # Add the encoded sentence to the list.\n","      input_ids.append(encoded_dict['input_ids'])\n","\n","      # And its attention mask (simply differentiates padding from non-padding).\n","      attention_masks.append(encoded_dict['attention_mask'])\n","  return input_ids, attention_masks"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":23724,"status":"ok","timestamp":1684273822060,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"jnzRtFdNA-nw","colab":{"base_uri":"https://localhost:8080/","height":276,"referenced_widgets":["dfa79ddde383449781633297a9f04fb2","ee0f0766010c4e978961533ef786e85f","6c4040b67b4f4dca8faeb8268c3b6fe9","d02bfcf3ded94d229304bf972c82fe18","5ec19ca25a6b48c194cf61392842e6f5","2e7d2e15fcae4574b5e8ebcf5be10ef8","003382d84bc149f6a6545e28849d4249","25724132cc9a4f189daffd4a0c2e4932","4f83d2622b264bfa9b76d2de63d9623b","910cb3d752c643188a6304872ea3498e","af931ab6282749b9b7cc3df7813ff345","abd1143b11524d5fb99681f69ed55c8b","d0105b95c26f42d0ad3a97e3f6bb8c91","496b880797a74f0997a5bade13be9fa7","2ad51560b6d745238e490df3b81a3b18","e07cbc8f1b8e458f9465818a0d47fa69","764a5ce38eed417783167d7eec1dff2a","5f5a678067a34d8b94bd2377099146e5","378972b5b4df47a3b657273dbc14478f","fd62e50e0efc4b07a2ec5bb79e7ed89e","ee1198b5761343d0aacef478a03fedf1","d3ea8001e62146dd81b8db7e21c9d56b","d6165bb5a6c54d2baf52ec2566d3d7f3","4c55379c4ce4402ca5ede8d6978d965f","9b55c2295af041b8a6a0369ad1a35bb0","3ec6089b78de45cf97a8b5af7f4ec005","fc0d701f1adb4d51b67b71fa10caad4a","1308352563ee4756a3dade4e01fa69c6","cefcf35d9fdf478dadbd37d586172324","80ccc8cab9f749a58839df5040a0d905","fb9bc354afc347ad9b6df680d58058b9","08905752b5214798923c7d1249a40eae","beb5adf4adef4e74b79cc8b1e36f8a28"]},"outputId":"99b0293e-717f-4ec9-87f1-61db75270867"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa79ddde383449781633297a9f04fb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abd1143b11524d5fb99681f69ed55c8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6165bb5a6c54d2baf52ec2566d3d7f3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original:  saw mill valley film festival hard believe ms bloms directorial debut beautifully paced performed large cast characters could anne tyler novel ie layered back story potential futures false notes surprising bursts humor amidst selfinflicted anxiety real earthshattering dilemmas saw best youth recognize well drawn characters small moments even story moves briskly along really hope gets distribution usa live fairly sophisticated film market yet rarely get swedish films kind\n","Token IDs: tensor([[  101,  2387,  4971,  3028,  2143,  2782,  2524,  2903,  5796,  1038,\n","         21297,  2015, 21635,  2834, 17950, 13823,  2864,  2312,  3459,  3494,\n","          2071,  4776,  7482,  3117, 29464, 21323,  2067,  2466,  4022, 17795,\n","          6270,  3964, 11341, 19239,  8562, 17171,  2969,  2378, 29301,  2098,\n","         10089,  2613,  3011,  7377, 19567, 21883,  2015,  2387,  2190,  3360,\n","          6807,  2092,  4567,  3494,  2235,  5312,  2130,  2466,  5829, 28022,\n","          2135,  2247,  2428,   102]])\n"]}],"source":["#tokenize train, test and val individually\n","\n","# For train\n","\n","texts = train_set.text.values\n","labels = train_set.sentiment.values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_train = torch.cat(input_ids, dim=0)\n","attention_masks_train = torch.cat(attention_masks, dim=0)\n","labels_train = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3313,"status":"ok","timestamp":1684273825354,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"8NqMcjxpBDPT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"66ef024d-5dba-4276-bef6-39ef6bf5bfed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  one movies dont require brain thinking funny time pass forgot next hour really surprised john abrahams acting usually playing gangster like character emotionless faceso playing complete opposite successfullyby managing shine amongst comic geniuses paresh rawal akshaye kumar also quite surprised akshayes girls roles dont require much talent mostly moaning akshayes dissapearenceto girls surprised managed establish actual persona could differentiate good thing also majority songs goodit colourful fun boring sunday evening sure lighten mood\n","Token IDs: tensor([[  101,  2028,  5691,  2123,  2102,  5478,  4167,  3241,  6057,  2051,\n","          3413,  9471,  2279,  3178,  2428,  4527,  2198,  8181,  2015,  3772,\n","          2788,  2652, 20067,  2066,  2839,  7603,  3238,  5344,  2080,  2652,\n","          3143,  4500,  5147,  3762,  6605, 12342,  5921,  5021, 11067,  2229,\n","         11968,  9953,  6315,  2389, 17712,  7377,  6672,  9600,  2036,  3243,\n","          4527, 17712,  7377, 23147,  3057,  4395,  2123,  2102,  5478,  2172,\n","          5848,  3262, 22653,   102]])\n"]}],"source":["# For test\n","\n","texts = test_set.text.values\n","labels = test_set.sentiment.values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids, dim=0)\n","attention_masks_test = torch.cat(attention_masks, dim=0)\n","labels_test = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5780,"status":"ok","timestamp":1684273870197,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"FaxUSrSEBGCv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"875fa4fb-bfe8-4385-c235-eeb39aa37120"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  govind nihalanis directorial venture vijay tendulkars novel brilliant om puri plays inspector velankar forced protect underworld rama shetty played brilliantly sadahiv amrapurkar govind nihlans talked movie good classic film smita patil plays female lead opposite om puri naseeruddin shah brilliant cameo role although sadashiv amrapurkar scenes movie dominates movie sadashiv amrapurkars acting debutom puri national award film best actor filmfare award winner best filmstorysupporting actorsadashiv amrapurkar\n","Token IDs: tensor([[  101, 18079, 22254,  9152, 19531,  8977, 21635,  6957, 17027,  7166,\n","          5313,  6673,  2015,  3117,  8235, 18168, 16405,  3089,  3248,  7742,\n","          2310,  5802,  6673,  3140,  4047, 13607, 14115,  2016, 15353,  2209,\n","          8235,  2135,  6517,  4430, 12848,  2572,  2527,  5311,  6673, 18079,\n","         22254,  9152,  7317,  6962,  5720,  3185,  2204,  4438,  2143, 15488,\n","          6590,  6986,  4014,  3248,  2931,  2599,  4500, 18168, 16405,  3089,\n","         17235, 11510, 17375,   102]])\n"]}],"source":["# For val\n","\n","texts = val_set.text.values\n","labels = val_set.sentiment.values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_val = torch.cat(input_ids, dim=0)\n","attention_masks_val = torch.cat(attention_masks, dim=0)\n","labels_val = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1684273870198,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"99ThBMa9BIee","colab":{"base_uri":"https://localhost:8080/"},"outputId":"99c87137-c88b-43d9-e5c8-df3ec07fa6e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Set Size:  6999\n","Validation Set Size:  2010\n","Test Set Size:  991\n"]}],"source":["#printing out len of train,test val\n","total = len(df)\n","num_train = len(train_set)\n","num_val = len(val_set)\n","num_test = len(test_set)\n","\n","print('Train Set Size: ',num_train)\n","print('Validation Set Size: ',num_val)\n","print('Test Set Size: ',num_test)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Fb31-4s8BL8C","executionInfo":{"status":"ok","timestamp":1684273870198,"user_tz":240,"elapsed":7,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[],"source":["# make lists of 3-tuples \n","\n","train_dataset=[]\n","for i in range(num_train):\n","  train_dataset.append((input_ids_train[i], attention_masks_train[i], labels_train[i]))\n","\n","val_dataset=[]\n","for i in range(num_val):\n","  val_dataset.append((input_ids_val[i], attention_masks_val[i], labels_val[i]))\n","\n","\n","test_dataset=[]\n","for i in range(num_test):\n","  test_dataset.append((input_ids_test[i], attention_masks_test[i], labels_test[i]))"]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"JEscHvRahGrF"}},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5151,"status":"ok","timestamp":1684273875342,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"},"user_tz":240},"id":"3zPTOMIyXusV","colab":{"base_uri":"https://localhost:8080/","height":194,"referenced_widgets":["128d396c5bed45048e4e08f34f03714f","e87b39e153e445afabde31fefd924039","9ddfb2f210c54eac9f9e86de27d5dc1c","cf556b76dc0549b2bb372f7094ad3f25","a84b69d617ff4eb38fbbb89ff1b60694","09a6e6e3317d48c48649415b35a9040d","b68d4a8b81a04183ae98f21ea8ed0f93","13253c93cf934942b6e01f59b23abc8e","37c18c991d8b402a8d7dff7b98356043","cb448893ae2f4b9ebf22e63e536883c3","647b0965b2a1445da6e329bbb868f87c"]},"outputId":"d7532820-fecb-431c-ba9b-b9e9ed0056cc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"128d396c5bed45048e4e08f34f03714f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["from transformers import AdamW, ElectraForSequenceClassification, get_linear_schedule_with_warmup\n","\n","model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=2)\n","#model.cuda()\n","\n","# Set the optimizer and learning rate scheduler\n","optimizer = AdamW(model.parameters(), lr=3e-5, eps=1e-8)\n","total_steps = len(train_dataset) * 4\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"EGRQHrohUUkI","executionInfo":{"status":"ok","timestamp":1684273875342,"user_tz":240,"elapsed":5,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[],"source":["# # Define the training loop\n","# from tqdm.auto import tqdm\n","\n","# model.to(device)\n","\n","# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n","# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# best_val_loss = float(\"inf\")\n","# num_epochs = 3\n","# train_loss = []\n","# val_loss = []\n","# for epoch in range(num_epochs):\n","#   # Train the model\n","#   model.train()\n","#   epoch_loss = 0\n","\n","#   train_loop = tqdm(train_loader, desc=f'Training Epoch {epoch+1}', leave=True)\n","\n","#   for batch in train_loop:\n","      \n","#     inputs = {'input_ids': batch[0].to(device),\n","#               'attention_mask': batch[1].to(device),\n","#               'labels': batch[2].to(device)}\n","#     optimizer.zero_grad()\n","#     outputs = model(**inputs)\n","#     loss = outputs[0]\n","\n","#     loss.backward()\n","#     optimizer.step()\n","#     scheduler.step()\n","\n","#     epoch_loss += loss.item()\n","#     train_loop.set_postfix(loss=loss.item())\n","\n","#   epoch_loss /= len(train_loader)\n","#   train_loss.append(epoch_loss)\n","\n","#   # Evaluate the model on the validation set\n","#   model.eval()\n","#   val_preds = []\n","#   val_labels = []\n","#   epoch_val_loss = 0\n","\n","#   with torch.no_grad():\n","#     for batch in val_loader:\n","        \n","#       inputs = {'input_ids': batch[0].to(device),\n","#                 'attention_mask': batch[1].to(device),\n","#                 'labels': batch[2].to(device)}\n","      \n","#       outputs = model(**inputs)\n","#       loss = outputs[0]\n","#       epoch_val_loss += loss.item()\n","\n","#       logits = outputs[1]\n","#       preds = torch.argmax(logits, axis=1)\n","#       val_preds.extend(preds.cpu().numpy())\n","#       val_labels.extend(batch[2].cpu().numpy())\n","\n","#     epoch_val_loss /= len(val_loader)\n","\n","#   if epoch_val_loss < best_val_loss:\n","#     best_val_loss = epoch_val_loss\n","#     # torch.save(model.state_dict(), \"t5_sentiment_model.pt\")\n","#     path = '/content/gdrive/MyDrive/NLP Project/models/ELECTRA_SA_CLEAN100'\n","\n","#     torch.save(model.state_dict(), path+'/model_parameters.pth')\n","\n","#   # Compute the evaluation metrics\n","#   val_accuracy = accuracy_score(val_labels, val_preds)\n","#   val_report = classification_report(val_labels, val_preds, target_names=['positive', 'negative'])\n","  \n","\n","#   # Print the results for the current epoch\n","#   print('Epoch:', epoch+1, ', Training Loss:', epoch_loss/len(train_loader), ', Validation Loss:', epoch_val_loss, ', Validation Accuracy:', val_accuracy)\n","#   print('Validation Classification Report:')\n","#   print(val_report)\n","    "]},{"cell_type":"code","execution_count":17,"metadata":{"id":"tGF9sm1EBbAH","executionInfo":{"status":"ok","timestamp":1684273875343,"user_tz":240,"elapsed":5,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"outputs":[],"source":["# Save model state dict in folder\n","\n","#path = '/content/gdrive/MyDrive/NLP Project/models/ELECTRA_SA_CLEAN100'\n","\n","#torch.save(model.state_dict(), path+'/model_parameters.pth')"]},{"cell_type":"markdown","source":["### Evaluation on Clean Data"],"metadata":{"id":"549L4u1XQ7cE"}},{"cell_type":"code","source":["import torch\n","\n","# Specify device\n","device = torch.device('cpu')\n","\n","# Load model for evaluations, comment for finetuning\n","path = '/content/gdrive/MyDrive/NLP Project/models/ELECTRA_SA_CLEAN100'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth', map_location=device))"],"metadata":{"id":"TAZzpVuDQ9j7","executionInfo":{"status":"ok","timestamp":1684273954657,"user_tz":240,"elapsed":3800,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9819f73-07a6-4244-da6d-69d6b7e8c424"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["model.to(device)\n","input_ids_test = input_ids_test.to(device)\n","attention_masks_test = attention_masks_test.to(device)\n","labels_test = labels_test.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids=input_ids_test, attention_mask=attention_masks_test)\n","    logits = outputs.logits\n","\n","# Apply softmax to obtain probabilities\n","probs = torch.softmax(logits, dim=1)\n","preds = torch.argmax(probs, dim=1)\n","\n","# Move predictions and labels back to CPU for evaluation\n","preds = preds.detach().cpu().numpy()\n","labels_test = labels_test.cpu().numpy()\n","\n","# Calculate accuracy\n","accuracy = (preds == labels_test).mean()\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n","\n","\n","\n"],"metadata":{"id":"daKkFXW0RCll","executionInfo":{"status":"ok","timestamp":1684267112126,"user_tz":240,"elapsed":203433,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"79b4c0a1-8b3e-4564-b8df-73e6ea890044"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.8163\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","f1 = f1_score(labels_test, preds, average='weighted')\n","print(f'F1 Score: {f1:.4f}')"],"metadata":{"id":"4jSptK0fXR9B","executionInfo":{"status":"ok","timestamp":1684267112126,"user_tz":240,"elapsed":5,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ce86b7e-6ad7-495d-8bf4-5642a89bf4ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 0.8137\n"]}]},{"cell_type":"markdown","source":["### Evaluation on Noisy data"],"metadata":{"id":"dpdDWvtMK2C_"}},{"cell_type":"code","source":["# Noise funcs \n","\n","char_action = ['insert',\n","        'substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","word_action = ['substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","\n","def get_action(type):\n","  if type==\"char\":\n","    return random.choice(char_action)\n","  elif type==\"word\":\n","    return random.choice(word_action)\n","\n","\n","def augment_tweet(tweet, p=0.7):\n","    \"\"\"\n","    Augment a tweet with character-level and word-level noise.\n","\n","    Args:\n","        tweet (str): The original tweet.\n","        p (float): The probability of applying the char level augmentation.\n","\n","    Returns:\n","        str: The augmented tweet.\n","    \"\"\"\n","    # Define a list of character-level augmentation techniques\n","    char_augmenters = [\n","        nac.OcrAug(),\n","        nac.KeyboardAug(aug_char_p=0.2, aug_word_p=0.2, include_special_char=False),\n","        nac.RandomCharAug(action=get_action(\"char\"), aug_char_p=0.1, aug_word_p=0.1),\n","    ]\n","\n","    # Define a list of word-level augmentation techniques\n","    word_augmenters = [\n","        naw.SpellingAug(),\n","        naw.SplitAug(),\n","        naw.SynonymAug(),\n","        naw.RandomWordAug(aug_p=0.2, action=get_action(\"word\")),\n","    ]\n","\n","    # Randomly apply a character-level or word-level augmentation with probability p\n","    if random.random() < p:\n","        aug = random.choice(char_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","    else:\n","        aug = random.choice(word_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","        \n","    return augmented_tweet\n","\n","def add_noise(df, augmentation_percentage, task):\n","\n","  if task==\"sentiment_analysis\":\n","    # Sample 10% of the rows in the DataFrame\n","    augment_indices = df.sample(frac=augmentation_percentage).index\n","\n","    # Apply the augment_tweet function to each tweet in the sampled rows\n","    for index in augment_indices:\n","        tweet = df.loc[index, 'text']\n","        augmented_tweet = augment_tweet(tweet)\n","        df.loc[index, 'text'] = augmented_tweet\n","    \n","    return df\n","  \n","  elif task==\"question_answering\":\n","\n","    # TODO - noise functions for QA\n","\n","    return df"],"metadata":{"id":"c2MeWD9cKws3","executionInfo":{"status":"ok","timestamp":1684274766104,"user_tz":240,"elapsed":201,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["import random\n","random.seed(42)\n","random_noise = random.uniform(0.05, 0.15)\n","print(random_noise)\n","\n","# Download data for Testing\n","df_test = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","df_test = df_test.rename(columns={'review':'text'})\n","df_test = df_test[['text', 'sentiment']]\n","\n"," \n","# How much of the dataset to use\n","data_size = 0.2\n","df_test = df_test.sample(frac=data_size, random_state=42)\n","\n","df_test['text'] = df_test['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","df_test['sentiment'] = df_test['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = df_test[df_test['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","df_test.drop(empty_rows.index, inplace=True)\n","\n","df_test = add_noise(df_test, augmentation_percentage=random_noise, task=\"sentiment_analysis\")\n","\n","# Separate the dataset into three subsets based on the sentiment labels\n","positive_reviews = df_test[df_test['sentiment'] == sentiment_map['positive']]\n","negative_reviews = df_test[df_test['sentiment'] == sentiment_map['negative']]\n","\n","# Shuffle each of the two subsets randomly\n","positive_reviews = positive_reviews.sample(frac=1, random_state=42)\n","negative_reviews = negative_reviews.sample(frac=1, random_state=42)\n","\n","print(len(positive_reviews), len(negative_reviews))\n","# Divide each subset into training, validation, and test sets with a 70/20/10 ratio\n","train_pos, val_pos_test_pos = train_test_split(positive_reviews, test_size=0.3, random_state=42)\n","val_pos, test_pos = train_test_split(val_pos_test_pos, test_size=0.33, random_state=42)\n","\n","train_neg, val_neg_test_neg = train_test_split(negative_reviews, test_size=0.3, random_state=42)\n","val_neg, test_neg = train_test_split(val_neg_test_neg, test_size=0.33, random_state=42)\n","\n","# Merge the corresponding subsets from each sentiment back together to form the final training, validation, and test sets\n","train_set = pd.concat([train_pos, train_neg], ignore_index=True)\n","val_set = pd.concat([val_pos, val_neg], ignore_index=True)\n","test_set = pd.concat([test_pos, test_neg], ignore_index=True)\n","\n","# For test\n","\n","texts = test_set.text.values\n","labels = test_set.sentiment.values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids, dim=0)\n","attention_masks_test = torch.cat(attention_masks, dim=0)\n","labels_test = torch.tensor(labels)\n","\n","\n","test_dataset=[]\n","for i in range(num_test):\n","  test_dataset.append((input_ids_test[i], attention_masks_test[i], labels_test[i]))\n","\n","import torch\n","\n","# Specify device\n","device = torch.device('cpu')\n","\n","# Load model for evaluations, comment for finetuning\n","path = '/content/gdrive/MyDrive/NLP Project/models/ELECTRA_SA_CLEAN100'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth', map_location=device))\n","\n","model.to(device)\n","input_ids_test = input_ids_test.to(device)\n","attention_masks_test = attention_masks_test.to(device)\n","labels_test = labels_test.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids=input_ids_test, attention_mask=attention_masks_test)\n","    logits = outputs.logits\n","\n","# Apply softmax to obtain probabilities\n","probs = torch.softmax(logits, dim=1)\n","preds = torch.argmax(probs, dim=1)\n","\n","# Move predictions and labels back to CPU for evaluation\n","preds = preds.detach().cpu().numpy()\n","labels_test = labels_test.cpu().numpy()\n","\n","# Calculate accuracy\n","accuracy = (preds == labels_test).mean()\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n","from sklearn.metrics import f1_score\n","\n","f1 = f1_score(labels_test, preds, average='weighted')\n","print(f'F1 Score: {f1:.4f}')"],"metadata":{"id":"EZyysKlrLbsZ","executionInfo":{"status":"ok","timestamp":1684267333602,"user_tz":240,"elapsed":221479,"user":{"displayName":"Anirudh Lakkaraju","userId":"12994454154978193314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d9487bd-53d6-44ce-fc6e-fe5e78fc01b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.11394267984578837\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["5039 4961\n","Test Accuracy: 0.7810\n","F1 Score: 0.7805\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1DwDi6zBiwpOEsnkdrZUWotLeNYMUjzqA","timestamp":1683843650649},{"file_id":"1m_3Zcx57629wlNaV6OXeXdgwsMAVjeDH","timestamp":1682977291393}],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dfa79ddde383449781633297a9f04fb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee0f0766010c4e978961533ef786e85f","IPY_MODEL_6c4040b67b4f4dca8faeb8268c3b6fe9","IPY_MODEL_d02bfcf3ded94d229304bf972c82fe18"],"layout":"IPY_MODEL_5ec19ca25a6b48c194cf61392842e6f5"}},"ee0f0766010c4e978961533ef786e85f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e7d2e15fcae4574b5e8ebcf5be10ef8","placeholder":"​","style":"IPY_MODEL_003382d84bc149f6a6545e28849d4249","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"6c4040b67b4f4dca8faeb8268c3b6fe9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25724132cc9a4f189daffd4a0c2e4932","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f83d2622b264bfa9b76d2de63d9623b","value":231508}},"d02bfcf3ded94d229304bf972c82fe18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_910cb3d752c643188a6304872ea3498e","placeholder":"​","style":"IPY_MODEL_af931ab6282749b9b7cc3df7813ff345","value":" 232k/232k [00:00&lt;00:00, 4.81MB/s]"}},"5ec19ca25a6b48c194cf61392842e6f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e7d2e15fcae4574b5e8ebcf5be10ef8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"003382d84bc149f6a6545e28849d4249":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25724132cc9a4f189daffd4a0c2e4932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f83d2622b264bfa9b76d2de63d9623b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"910cb3d752c643188a6304872ea3498e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af931ab6282749b9b7cc3df7813ff345":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abd1143b11524d5fb99681f69ed55c8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0105b95c26f42d0ad3a97e3f6bb8c91","IPY_MODEL_496b880797a74f0997a5bade13be9fa7","IPY_MODEL_2ad51560b6d745238e490df3b81a3b18"],"layout":"IPY_MODEL_e07cbc8f1b8e458f9465818a0d47fa69"}},"d0105b95c26f42d0ad3a97e3f6bb8c91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_764a5ce38eed417783167d7eec1dff2a","placeholder":"​","style":"IPY_MODEL_5f5a678067a34d8b94bd2377099146e5","value":"Downloading (…)okenizer_config.json: 100%"}},"496b880797a74f0997a5bade13be9fa7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_378972b5b4df47a3b657273dbc14478f","max":27,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd62e50e0efc4b07a2ec5bb79e7ed89e","value":27}},"2ad51560b6d745238e490df3b81a3b18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee1198b5761343d0aacef478a03fedf1","placeholder":"​","style":"IPY_MODEL_d3ea8001e62146dd81b8db7e21c9d56b","value":" 27.0/27.0 [00:00&lt;00:00, 434B/s]"}},"e07cbc8f1b8e458f9465818a0d47fa69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"764a5ce38eed417783167d7eec1dff2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f5a678067a34d8b94bd2377099146e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"378972b5b4df47a3b657273dbc14478f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd62e50e0efc4b07a2ec5bb79e7ed89e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee1198b5761343d0aacef478a03fedf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ea8001e62146dd81b8db7e21c9d56b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6165bb5a6c54d2baf52ec2566d3d7f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c55379c4ce4402ca5ede8d6978d965f","IPY_MODEL_9b55c2295af041b8a6a0369ad1a35bb0","IPY_MODEL_3ec6089b78de45cf97a8b5af7f4ec005"],"layout":"IPY_MODEL_fc0d701f1adb4d51b67b71fa10caad4a"}},"4c55379c4ce4402ca5ede8d6978d965f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1308352563ee4756a3dade4e01fa69c6","placeholder":"​","style":"IPY_MODEL_cefcf35d9fdf478dadbd37d586172324","value":"Downloading (…)lve/main/config.json: 100%"}},"9b55c2295af041b8a6a0369ad1a35bb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80ccc8cab9f749a58839df5040a0d905","max":666,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb9bc354afc347ad9b6df680d58058b9","value":666}},"3ec6089b78de45cf97a8b5af7f4ec005":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08905752b5214798923c7d1249a40eae","placeholder":"​","style":"IPY_MODEL_beb5adf4adef4e74b79cc8b1e36f8a28","value":" 666/666 [00:00&lt;00:00, 21.4kB/s]"}},"fc0d701f1adb4d51b67b71fa10caad4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1308352563ee4756a3dade4e01fa69c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cefcf35d9fdf478dadbd37d586172324":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80ccc8cab9f749a58839df5040a0d905":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb9bc354afc347ad9b6df680d58058b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08905752b5214798923c7d1249a40eae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"beb5adf4adef4e74b79cc8b1e36f8a28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"128d396c5bed45048e4e08f34f03714f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e87b39e153e445afabde31fefd924039","IPY_MODEL_9ddfb2f210c54eac9f9e86de27d5dc1c","IPY_MODEL_cf556b76dc0549b2bb372f7094ad3f25"],"layout":"IPY_MODEL_a84b69d617ff4eb38fbbb89ff1b60694"}},"e87b39e153e445afabde31fefd924039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09a6e6e3317d48c48649415b35a9040d","placeholder":"​","style":"IPY_MODEL_b68d4a8b81a04183ae98f21ea8ed0f93","value":"Downloading pytorch_model.bin: 100%"}},"9ddfb2f210c54eac9f9e86de27d5dc1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13253c93cf934942b6e01f59b23abc8e","max":440343552,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37c18c991d8b402a8d7dff7b98356043","value":440343552}},"cf556b76dc0549b2bb372f7094ad3f25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb448893ae2f4b9ebf22e63e536883c3","placeholder":"​","style":"IPY_MODEL_647b0965b2a1445da6e329bbb868f87c","value":" 440M/440M [00:03&lt;00:00, 156MB/s]"}},"a84b69d617ff4eb38fbbb89ff1b60694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09a6e6e3317d48c48649415b35a9040d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b68d4a8b81a04183ae98f21ea8ed0f93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13253c93cf934942b6e01f59b23abc8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37c18c991d8b402a8d7dff7b98356043":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb448893ae2f4b9ebf22e63e536883c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"647b0965b2a1445da6e329bbb868f87c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}