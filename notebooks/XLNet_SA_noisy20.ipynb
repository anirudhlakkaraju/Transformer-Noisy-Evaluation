{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1CCg3OhOmSJKbjKfSLCiPOA3opKqe3lQm","timestamp":1684008762774},{"file_id":"1AtPCrdJOYAPSxeD-51jKtDjSFLz3Aip3","timestamp":1683998413022}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"c7c0eca6eb0742a7bf6a57d383527d4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c0ee85d54d4446db1d7d989ed4f4364","IPY_MODEL_bf41417a67684edaac8ee7f4f2e1f594","IPY_MODEL_49879c2fe4a841faa87e0c70a495f93c"],"layout":"IPY_MODEL_b539b276227745c392fd847381f0eab9"}},"5c0ee85d54d4446db1d7d989ed4f4364":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7111263dbbc24d029f9cf45221904e2f","placeholder":"​","style":"IPY_MODEL_9d6c7f4651924a01a6aad4d624e676ea","value":"Downloading (…)ve/main/spiece.model: 100%"}},"bf41417a67684edaac8ee7f4f2e1f594":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fcc11a8cda14b0dbe0b49c3102870b4","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d75347950508447ba9d64fc02eea4401","value":798011}},"49879c2fe4a841faa87e0c70a495f93c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff07261a080247bb96b03b27cbaf09c9","placeholder":"​","style":"IPY_MODEL_9e7b7c8e8cf24771a6c2205f89c13807","value":" 798k/798k [00:00&lt;00:00, 3.17MB/s]"}},"b539b276227745c392fd847381f0eab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7111263dbbc24d029f9cf45221904e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d6c7f4651924a01a6aad4d624e676ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fcc11a8cda14b0dbe0b49c3102870b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d75347950508447ba9d64fc02eea4401":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff07261a080247bb96b03b27cbaf09c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e7b7c8e8cf24771a6c2205f89c13807":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a926a0a255e94d439ebf9a6fffc2a2e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5edb12376304e08ac07eb255bfe9585","IPY_MODEL_4ce00987fc3644b0ba84451223f39339","IPY_MODEL_e02fa38ba9b548ee942d2367792dad93"],"layout":"IPY_MODEL_52e855d031e44c16b321c40d80f0ed13"}},"e5edb12376304e08ac07eb255bfe9585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10786ffbcf834ae29ecf0a19f493a945","placeholder":"​","style":"IPY_MODEL_ccefd73774394748a14fd9a747412a41","value":"Downloading (…)lve/main/config.json: 100%"}},"4ce00987fc3644b0ba84451223f39339":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_458bdb71789649d59f0df8feef05835a","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9f37b51932c4e6189353c105d9ce8d7","value":760}},"e02fa38ba9b548ee942d2367792dad93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1161e1ac2bbf4094a0ea5b2435945e17","placeholder":"​","style":"IPY_MODEL_fdbb8c961f444472963eca2fd8ef0947","value":" 760/760 [00:00&lt;00:00, 51.3kB/s]"}},"52e855d031e44c16b321c40d80f0ed13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10786ffbcf834ae29ecf0a19f493a945":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccefd73774394748a14fd9a747412a41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"458bdb71789649d59f0df8feef05835a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9f37b51932c4e6189353c105d9ce8d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1161e1ac2bbf4094a0ea5b2435945e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdbb8c961f444472963eca2fd8ef0947":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffa8405937d141248fd7e7530fcd2322":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c4272d011534b9495e61f84692e8462","IPY_MODEL_8f147af8d8a44d3987d5ebd6816d786d","IPY_MODEL_055987978e6e4eb5b797195aec1db865"],"layout":"IPY_MODEL_0a190d565af04c1f860084d8ae2e5c9a"}},"4c4272d011534b9495e61f84692e8462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d03bcb5a7e14cf7b1f3a684f161d019","placeholder":"​","style":"IPY_MODEL_ac63aef33b1c4904a52b9dd082603796","value":"Downloading pytorch_model.bin: 100%"}},"8f147af8d8a44d3987d5ebd6816d786d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d139386a396a4bc5b8a4f711fae8019f","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a139541003e84147aa4b207186b5ad72","value":467042463}},"055987978e6e4eb5b797195aec1db865":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1b194d00ff145f5b7248105bc3143ec","placeholder":"​","style":"IPY_MODEL_82f1b32356084ba9925232f627b4db8e","value":" 467M/467M [00:01&lt;00:00, 258MB/s]"}},"0a190d565af04c1f860084d8ae2e5c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d03bcb5a7e14cf7b1f3a684f161d019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac63aef33b1c4904a52b9dd082603796":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d139386a396a4bc5b8a4f711fae8019f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a139541003e84147aa4b207186b5ad72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1b194d00ff145f5b7248105bc3143ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82f1b32356084ba9925232f627b4db8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qK7f50UXY14z","executionInfo":{"status":"ok","timestamp":1684185898373,"user_tz":240,"elapsed":17959,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"78ff91a0-441e-4d6d-f98c-6de9485dc5fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install -U -q PyDrive\n","!pip install \n","!pip install keras\n","!pip install sentencepiece\n","!pip install nlpaug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0T528qQZONO","executionInfo":{"status":"ok","timestamp":1684185931617,"user_tz":240,"elapsed":33252,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"54cc7cf9-2a87-4d62-ffdc-37e7edefa577"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n","\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}]},{"cell_type":"code","source":["!pip install pytorch-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prAWPFc4fyR2","executionInfo":{"status":"ok","timestamp":1684185953175,"user_tz":240,"elapsed":21402,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"7db0f5d0-09d6-4f62-d8eb-ac34c3e2215c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.0.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.22.4)\n","Collecting boto3 (from pytorch-transformers)\n","  Downloading boto3-1.26.134-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.65.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2022.10.31)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (0.1.99)\n","Collecting sacremoses (from pytorch-transformers)\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (16.0.3)\n","Collecting botocore<1.30.0,>=1.29.134 (from boto3->pytorch-transformers)\n","  Downloading botocore-1.29.134-py3-none-any.whl (10.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-transformers)\n","  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.2.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.134->boto3->pytorch-transformers) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=740da8e685baf3e5e85cdf711cca0b0d5ed8c5a2871eb077bd8b975e3f98588a\n","  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n","Successfully installed boto3-1.26.134 botocore-1.29.134 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.1 sacremoses-0.0.53\n"]}]},{"cell_type":"markdown","source":["###Imports"],"metadata":{"id":"w3_WmdQ_QAE4"}},{"cell_type":"code","source":["# Import required libraries\n","import torch\n","import pandas as pd\n","import numpy as np\n","import re\n","import random\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from transformers import XLNetTokenizer, XLNetForMultipleChoice\n","from sklearn.metrics import accuracy_score, classification_report,f1_score\n","import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw"],"metadata":{"id":"gPXeKXAwZauv","executionInfo":{"status":"ok","timestamp":1684185969193,"user_tz":240,"elapsed":16038,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3jAn5TCZcA0","executionInfo":{"status":"ok","timestamp":1684185969386,"user_tz":240,"elapsed":220,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"87b269d4-fcdf-4e09-86c1-cf4fd4b467e6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}]},{"cell_type":"markdown","source":["### Data download and preprocessing"],"metadata":{"id":"oUhDu8x2QIV0"}},{"cell_type":"code","source":["import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def clean_text(text):\n","    # Convert all text to lowercase\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    # Remove numbers\n","    text = re.sub(r'\\d+', '', text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = nltk.word_tokenize(text)\n","    tokens = [token for token in tokens if token not in stop_words]\n","    text = ' '.join(tokens)\n","\n","    # Remove extra whitespaces\n","    text = re.sub(' +', ' ', text)\n","\n","    return text"],"metadata":{"id":"lJb56kUQZgjq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684185970099,"user_tz":240,"elapsed":720,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"6312d1c9-d492-4827-9fa2-56d582e77736"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["\n","import pandas as pd\n","df = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","df = df.rename(columns={'review':'text'})\n","df = df[['text', 'sentiment']]\n","\n"," \n","# How much of the dataset to use\n","data_size = 0.2\n","df = df.sample(frac=data_size, random_state=42)\n","\n","df['text'] = df['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","df['sentiment'] = df['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = df[df['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","df.drop(empty_rows.index, inplace=True)"],"metadata":{"id":"attL3kgoZjYi","executionInfo":{"status":"ok","timestamp":1684185992296,"user_tz":240,"elapsed":22207,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"udOTsiSaZmNq","executionInfo":{"status":"ok","timestamp":1684185992297,"user_tz":240,"elapsed":58,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"ef07749e-f8bb-4b31-d726-08368cbec1d3"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    text  sentiment\n","33553  really liked summerslam due look arena curtain...          0\n","9427   many television shows appeal quite many differ...          0\n","199    film quickly gets major chase scene ever incre...          1\n","12447  jane austen would definitely approve onebr br ...          0\n","39489  expectations somewhat high went see movie thou...          1"],"text/html":["\n","  <div id=\"df-eb940f6f-0802-4ed5-8956-0eec3041d956\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>33553</th>\n","      <td>really liked summerslam due look arena curtain...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9427</th>\n","      <td>many television shows appeal quite many differ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>film quickly gets major chase scene ever incre...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12447</th>\n","      <td>jane austen would definitely approve onebr br ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>39489</th>\n","      <td>expectations somewhat high went see movie thou...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb940f6f-0802-4ed5-8956-0eec3041d956')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eb940f6f-0802-4ed5-8956-0eec3041d956 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eb940f6f-0802-4ed5-8956-0eec3041d956');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["###Noise Functions"],"metadata":{"id":"36czmvP7Ic3J"}},{"cell_type":"code","source":["# Noise funcs \n","\n","char_action = ['insert',\n","        'substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","word_action = ['substitute',\n","        'delete',\n","        'swap',\n","]\n","\n","\n","def get_action(type):\n","  if type==\"char\":\n","    return random.choice(char_action)\n","  elif type==\"word\":\n","    return random.choice(word_action)\n","\n","\n","def augment_tweet(tweet, p=0.7):\n","    \"\"\"\n","    Augment a tweet with character-level and word-level noise.\n","\n","    Args:\n","        tweet (str): The original tweet.\n","        p (float): The probability of applying the char level augmentation.\n","\n","    Returns:\n","        str: The augmented tweet.\n","    \"\"\"\n","    # Define a list of character-level augmentation techniques\n","    char_augmenters = [\n","        nac.OcrAug(),\n","        nac.KeyboardAug(aug_char_p=0.2, aug_word_p=0.2, include_special_char=False),\n","        nac.RandomCharAug(action=get_action(\"char\"), aug_char_p=0.1, aug_word_p=0.1),\n","    ]\n","\n","    # Define a list of word-level augmentation techniques\n","    word_augmenters = [\n","        naw.SpellingAug(),\n","        naw.SplitAug(),\n","        naw.SynonymAug(),\n","        naw.RandomWordAug(aug_p=0.2, action=get_action(\"word\")),\n","    ]\n","\n","    # Randomly apply a character-level or word-level augmentation with probability p\n","    if random.random() < p:\n","        aug = random.choice(char_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","    else:\n","        aug = random.choice(word_augmenters)\n","        augmented_tweet = aug.augment(tweet)\n","        \n","    return augmented_tweet\n","\n","def add_noise(df, augmentation_percentage, task):\n","\n","  if task==\"sentiment_analysis\":\n","    # Sample 10% of the rows in the DataFrame\n","    augment_indices = df.sample(frac=augmentation_percentage).index\n","\n","    # Apply the augment_tweet function to each tweet in the sampled rows\n","    for index in augment_indices:\n","        tweet = df.loc[index, 'text']\n","        augmented_tweet = augment_tweet(tweet)\n","        df.loc[index, 'text'] = augmented_tweet\n","    \n","    return df\n","  \n","  elif task==\"question_answering\":\n","\n","    #noise functions for QA\n","\n","    return df"],"metadata":{"id":"pTFuqtv0Ide2","executionInfo":{"status":"ok","timestamp":1684185992299,"user_tz":240,"elapsed":26,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#Adding noise of 20%\n","# Add word and char level noise 20%\n","df = add_noise(df, augmentation_percentage=0.2, task=\"sentiment_analysis\")\n","\n","# Randomly shuffle all rows\n","df = df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"wtMyWrBDIlbS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684186012043,"user_tz":240,"elapsed":19769,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"a450f21f-439a-4c6d-e95f-aa50dde16f4f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"code","source":["texts = df.text.values\n","texts = [''.join(text) + \" [SEP] [CLS]\" for text in texts]\n","sentiment = df.sentiment.values"],"metadata":{"id":"_NyXlFMAaUiZ","executionInfo":{"status":"ok","timestamp":1684186012043,"user_tz":240,"elapsed":8,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n","\n","tokenized_texts = [tokenizer.tokenize(text) for text in texts]\n","print (\"Tokenize the first sentence:\")\n","print (tokenized_texts[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["c7c0eca6eb0742a7bf6a57d383527d4c","5c0ee85d54d4446db1d7d989ed4f4364","bf41417a67684edaac8ee7f4f2e1f594","49879c2fe4a841faa87e0c70a495f93c","b539b276227745c392fd847381f0eab9","7111263dbbc24d029f9cf45221904e2f","9d6c7f4651924a01a6aad4d624e676ea","2fcc11a8cda14b0dbe0b49c3102870b4","d75347950508447ba9d64fc02eea4401","ff07261a080247bb96b03b27cbaf09c9","9e7b7c8e8cf24771a6c2205f89c13807","a926a0a255e94d439ebf9a6fffc2a2e6","e5edb12376304e08ac07eb255bfe9585","4ce00987fc3644b0ba84451223f39339","e02fa38ba9b548ee942d2367792dad93","52e855d031e44c16b321c40d80f0ed13","10786ffbcf834ae29ecf0a19f493a945","ccefd73774394748a14fd9a747412a41","458bdb71789649d59f0df8feef05835a","f9f37b51932c4e6189353c105d9ce8d7","1161e1ac2bbf4094a0ea5b2435945e17","fdbb8c961f444472963eca2fd8ef0947"]},"id":"XvBoM20lasIp","executionInfo":{"status":"ok","timestamp":1684186028746,"user_tz":240,"elapsed":16710,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"38ca35ba-5846-4832-89c1-aa75d179be0e"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7c0eca6eb0742a7bf6a57d383527d4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a926a0a255e94d439ebf9a6fffc2a2e6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenize the first sentence:\n","['▁savage', 'd', '▁came', '▁film', '▁looks', '▁handsome', '▁sounds', '▁great', '▁feast', '▁intelligent', '▁thoughtful', '▁acting', '▁', 'gi', 'el', 'gu', 'd', '▁', 'ken', 'ne', 'th', '▁ha', 'igh', '▁harr', 'y', '▁and', 'rew', 's', '▁especially', '▁an', 'ton', '▁', 'wal', 'brook', 'and', '▁moving', '▁central', '▁performance', '▁beautiful', '▁incredibly', '▁young', '▁', 'je', 'an', '▁', 'se', 'berg', '▁pre', 'ming', 'er', '▁doesn', 't', '▁jump', '▁around', '▁show', '▁long', '▁slow', '▁takes', '▁encourage', '▁listen', '▁reflect', '▁', 'gra', 'ham', '▁green', 'es', '▁script', '▁condense', 's', '▁', 'shaw', '▁without', '▁', 'sac', 'r', 'ific', 'ing', '▁complexity', 'the', '▁piece', '▁look', '▁made', '▁', 'tv', '▁movie', '▁certainly', '▁studio', '▁bound', '▁none', '▁worse', '▁many', '▁contemporary', '▁movies', '▁historical', '▁themes', '▁resist', '▁dumb', 'ing', '▁would', '▁', 'mel', '▁', 'gi', 'b', 'son', '▁made', '▁', 'maid', '▁many', '▁', 'dro', 'ol', 'ing', '▁shots', '▁rack', '▁probably', '▁crisp', 'ing', '▁', 'bb', 'q', '▁flames', '▁take', '▁hold', '▁pre', 'ming', 'er', '▁none', '▁burning', '▁shown', '▁mainly', '▁guilt', 'stricken', '▁reaction', '▁weak', '▁performances', '▁enough', '▁cause', '▁serious', '▁damage', '▁caught', '▁movie', '▁', 'tv', '▁expecting', '▁watch', '▁gripped', '▁age', '▁religious', '▁fundamental', 'ism', '▁sacrifice', '▁', 'jo', 'ans', '▁story', '▁unexpected', '▁resonance', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"]}]},{"cell_type":"code","source":["input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"],"metadata":{"id":"B3whznChRfya","executionInfo":{"status":"ok","timestamp":1684186032318,"user_tz":240,"elapsed":3617,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Pad our input tokens\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","MAX_LEN = 512\n","\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"metadata":{"id":"qn9wdy33et4U","executionInfo":{"status":"ok","timestamp":1684186032590,"user_tz":240,"elapsed":280,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)"],"metadata":{"id":"VZemSsgWcR_e","executionInfo":{"status":"ok","timestamp":1684186034677,"user_tz":240,"elapsed":2092,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["### Train/val/test splits"],"metadata":{"id":"k3jx7-KVQhFl"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","\n","\n","\n","# Splits train/test/val -> 70/20/10\n","train_inputs, temp_inputs, train_labels, temp_labels = train_test_split(input_ids, sentiment,\n","                                                                        random_state=42, test_size=0.3)\n","\n","validation_inputs, test_inputs, validation_labels, test_labels = train_test_split(temp_inputs, temp_labels,\n","                                                                        random_state=42, test_size=0.33)\n","\n","# Masks in 70/20/10\n","train_masks, temp_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                                  random_state=42, test_size=0.3)\n","# \n","validation_masks, test_masks, _, _ = train_test_split(temp_masks, temp_inputs,\n","                                                  random_state=42, test_size=0.33)\n","\n","# Splitting train set into train and validation (70% train, 20% validation)\n","# train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs, train_labels,\n","#                                                                                     random_state=42, test_size=0.2)\n","\n","# train_masks, validation_masks, _, _ = train_test_split(train_masks, train_inputs,\n","#                                                        random_state=42, test_size=0.2)\n","\n"],"metadata":{"id":"uzKJ_Ag_cZAl","executionInfo":{"status":"ok","timestamp":1684186034677,"user_tz":240,"elapsed":6,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Convert all of our data into torch tensors, the required datatype for our model\n","\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","\n","test_inputs = torch.tensor(test_inputs)\n","test_masks = torch.tensor(test_masks)\n","test_labels = torch.tensor(test_labels)"],"metadata":{"id":"VXagmB9BeB64","executionInfo":{"status":"ok","timestamp":1684186035327,"user_tz":240,"elapsed":654,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n","batch_size = 16\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"],"metadata":{"id":"iNpWX6hbeMCl","executionInfo":{"status":"ok","timestamp":1684186035328,"user_tz":240,"elapsed":7,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"1CEb7Ia_QtZ1"}},{"cell_type":"code","source":["import torch\n","from transformers import XLNetForSequenceClassification, XLNetTokenizer\n","\n","model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676,"referenced_widgets":["ffa8405937d141248fd7e7530fcd2322","4c4272d011534b9495e61f84692e8462","8f147af8d8a44d3987d5ebd6816d786d","055987978e6e4eb5b797195aec1db865","0a190d565af04c1f860084d8ae2e5c9a","5d03bcb5a7e14cf7b1f3a684f161d019","ac63aef33b1c4904a52b9dd082603796","d139386a396a4bc5b8a4f711fae8019f","a139541003e84147aa4b207186b5ad72","e1b194d00ff145f5b7248105bc3143ec","82f1b32356084ba9925232f627b4db8e"]},"id":"GJTs4AMFfRk3","executionInfo":{"status":"ok","timestamp":1684186047527,"user_tz":240,"elapsed":12204,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"7821d658-816f-44e5-88e0-e09192cb0ac9"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffa8405937d141248fd7e7530fcd2322"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["XLNetForSequenceClassification(\n","  (transformer): XLNetModel(\n","    (word_embedding): Embedding(32000, 768)\n","    (layer): ModuleList(\n","      (0-11): 12 x XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (activation_function): GELUActivation()\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (sequence_summary): SequenceSummary(\n","    (summary): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","    (first_dropout): Identity()\n","    (last_dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n"],"metadata":{"id":"LXYFp_ySfqzJ","executionInfo":{"status":"ok","timestamp":1684186047528,"user_tz":240,"elapsed":67,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# This variable contains all of the hyperparemeter information our training loop needs\n","optimizer = AdamW(optimizer_grouped_parameters,\n","                     lr=2e-5)\n","\n","total_steps = len(train_data) * 4\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"],"metadata":{"id":"Fz_sJqztheuU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684186047528,"user_tz":240,"elapsed":66,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"02e91e0a-64fc-4169-f2b3-61c75956ce66"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["'''# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)'''"],"metadata":{"id":"QlUP01OYgzNy","executionInfo":{"status":"ok","timestamp":1684186047529,"user_tz":240,"elapsed":64,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"ebb1da39-1568-4254-fed8-6f7cf941d993"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Function to calculate the accuracy of our predictions vs labels\\ndef flat_accuracy(preds, labels):\\n    pred_flat = np.argmax(preds, axis=1).flatten()\\n    labels_flat = labels.flatten()\\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["#Commented fine-tuning for testing\n","'''from tqdm import tqdm, trange\n","best_val_loss = float(\"inf\")\n","num_epochs = 2\n","train_loss = []\n","val_loss = []\n","for epoch in range(num_epochs):\n","  # Train the model\n","  model.train()\n","  epoch_loss = 0\n","\n","  train_loop = tqdm(train_dataloader, desc=f'Training Epoch {epoch+1}', leave=True)\n","\n","  for batch in train_loop:\n","      \n","    inputs = {'input_ids': batch[0].to(device),\n","              'attention_mask': batch[1].to(device),\n","              'labels': batch[2].to(device)}\n","    optimizer.zero_grad()\n","    outputs = model(**inputs)\n","    loss = outputs[0]\n","\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    epoch_loss += loss.item()\n","    train_loop.set_postfix(loss=loss.item())\n","\n","  epoch_loss /= len(train_dataloader)\n","  train_loss.append(epoch_loss)\n","\n","  # Evaluate the model on the validation set\n","  model.eval()\n","  val_preds = []\n","  val_labels = []\n","  epoch_val_loss = 0\n","\n","  with torch.no_grad():\n","    for batch in validation_dataloader:\n","        \n","      inputs = {'input_ids': batch[0].to(device),\n","                'attention_mask': batch[1].to(device),\n","                'labels': batch[2].to(device)}\n","      \n","      outputs = model(**inputs)\n","      loss = outputs[0]\n","      epoch_val_loss += loss.item()\n","\n","      logits = outputs[1]\n","      preds = torch.argmax(logits, axis=1)\n","      val_preds.extend(preds.cpu().numpy())\n","      val_labels.extend(batch[2].cpu().numpy())\n","\n","    epoch_val_loss /= len(validation_dataloader)\n","\n","  if epoch_val_loss < best_val_loss:\n","    best_val_loss = epoch_val_loss\n","    \n","    path = '/content/gdrive/MyDrive/NLP Project/models/XLNet_SA_Noisy20'\n","\n","    torch.save(model.state_dict(), path+'/model_parameters.pth')\n","\n","  # Compute the evaluation metrics\n","  val_accuracy = accuracy_score(val_labels, val_preds)\n","  val_report = classification_report(val_labels, val_preds, target_names=['positive', 'negative'])\n","  \n","\n","  # Print the results for the current epoch\n","  print('Epoch:', epoch+1, ', Training Loss:', epoch_loss/len(train_dataloader), ', Validation Loss:', epoch_val_loss, ', Validation Accuracy:', val_accuracy)\n","  print('Validation Classification Report:')\n","  print(val_report)'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"GdNeAri4yoDN","executionInfo":{"status":"ok","timestamp":1684186047529,"user_tz":240,"elapsed":59,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"86ed0298-0f2c-42a7-ecfd-2266623a36f3"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'from tqdm import tqdm, trange\\nbest_val_loss = float(\"inf\")\\nnum_epochs = 2\\ntrain_loss = []\\nval_loss = []\\nfor epoch in range(num_epochs):\\n  # Train the model\\n  model.train()\\n  epoch_loss = 0\\n\\n  train_loop = tqdm(train_dataloader, desc=f\\'Training Epoch {epoch+1}\\', leave=True)\\n\\n  for batch in train_loop:\\n      \\n    inputs = {\\'input_ids\\': batch[0].to(device),\\n              \\'attention_mask\\': batch[1].to(device),\\n              \\'labels\\': batch[2].to(device)}\\n    optimizer.zero_grad()\\n    outputs = model(**inputs)\\n    loss = outputs[0]\\n\\n    loss.backward()\\n    optimizer.step()\\n    scheduler.step()\\n\\n    epoch_loss += loss.item()\\n    train_loop.set_postfix(loss=loss.item())\\n\\n  epoch_loss /= len(train_dataloader)\\n  train_loss.append(epoch_loss)\\n\\n  # Evaluate the model on the validation set\\n  model.eval()\\n  val_preds = []\\n  val_labels = []\\n  epoch_val_loss = 0\\n\\n  with torch.no_grad():\\n    for batch in validation_dataloader:\\n        \\n      inputs = {\\'input_ids\\': batch[0].to(device),\\n                \\'attention_mask\\': batch[1].to(device),\\n                \\'labels\\': batch[2].to(device)}\\n      \\n      outputs = model(**inputs)\\n      loss = outputs[0]\\n      epoch_val_loss += loss.item()\\n\\n      logits = outputs[1]\\n      preds = torch.argmax(logits, axis=1)\\n      val_preds.extend(preds.cpu().numpy())\\n      val_labels.extend(batch[2].cpu().numpy())\\n\\n    epoch_val_loss /= len(validation_dataloader)\\n\\n  if epoch_val_loss < best_val_loss:\\n    best_val_loss = epoch_val_loss\\n    \\n    path = \\'/content/gdrive/MyDrive/NLP Project/models/XLNet_SA_Noisy20\\'\\n\\n    torch.save(model.state_dict(), path+\\'/model_parameters.pth\\')\\n\\n  # Compute the evaluation metrics\\n  val_accuracy = accuracy_score(val_labels, val_preds)\\n  val_report = classification_report(val_labels, val_preds, target_names=[\\'positive\\', \\'negative\\'])\\n  \\n\\n  # Print the results for the current epoch\\n  print(\\'Epoch:\\', epoch+1, \\', Training Loss:\\', epoch_loss/len(train_dataloader), \\', Validation Loss:\\', epoch_val_loss, \\', Validation Accuracy:\\', val_accuracy)\\n  print(\\'Validation Classification Report:\\')\\n  print(val_report)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["###Evaluation on clean data"],"metadata":{"id":"coSrerrM1tPs"}},{"cell_type":"code","source":["\n","import pandas as pd\n","test_df = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","test_df = test_df.rename(columns={'review':'text'})\n","test_df = test_df[['text', 'sentiment']]\n","\n"," \n","# How much of the dataset to use\n","data_size = 0.2\n","test_df = test_df.sample(frac=data_size, random_state=42)\n","\n","test_df['text'] = test_df['text'].apply(clean_text)\n","\n","# Convert the sentiment labels into numerical values\n","sentiment_map = {'positive': 0, 'negative': 1}\n","test_df['sentiment'] = test_df['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = test_df[test_df['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","test_df.drop(empty_rows.index, inplace=True)"],"metadata":{"id":"rr3D1qosYZQA","executionInfo":{"status":"ok","timestamp":1684186057957,"user_tz":240,"elapsed":10485,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["texts = df.text.values\n","texts = [''.join(text) + \" [SEP] [CLS]\" for text in texts]\n","sentiment = df.sentiment.values\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n","\n","tokenized_texts = [tokenizer.tokenize(text) for text in texts]\n","print (\"Tokenize the first sentence:\")\n","print (tokenized_texts[0])\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# Pad our input tokens\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","MAX_LEN = 512\n","\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","\n","# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","\n","  from sklearn.model_selection import train_test_split\n","\n","\n","\n","\n","# Splits train/test/val -> 70/20/10\n","train_inputs, temp_inputs, train_labels, temp_labels = train_test_split(input_ids, sentiment,\n","                                                                        random_state=42, test_size=0.3)\n","\n","validation_inputs, test_inputs, validation_labels, test_labels = train_test_split(temp_inputs, temp_labels,\n","                                                                        random_state=42, test_size=0.33)\n","\n","# Masks in 70/20/10\n","train_masks, temp_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                                  random_state=42, test_size=0.3)\n","# \n","validation_masks, test_masks, _, _ = train_test_split(temp_masks, temp_inputs,\n","                                                  random_state=42, test_size=0.33)\n","\n","\n","test_inputs = torch.tensor(test_inputs)\n","test_masks = torch.tensor(test_masks)\n","test_labels = torch.tensor(test_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zn3WB3w6Yarx","executionInfo":{"status":"ok","timestamp":1684186081031,"user_tz":240,"elapsed":23079,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"c9d9c244-5183-403f-e194-c2a5099d1b84"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenize the first sentence:\n","['▁savage', 'd', '▁came', '▁film', '▁looks', '▁handsome', '▁sounds', '▁great', '▁feast', '▁intelligent', '▁thoughtful', '▁acting', '▁', 'gi', 'el', 'gu', 'd', '▁', 'ken', 'ne', 'th', '▁ha', 'igh', '▁harr', 'y', '▁and', 'rew', 's', '▁especially', '▁an', 'ton', '▁', 'wal', 'brook', 'and', '▁moving', '▁central', '▁performance', '▁beautiful', '▁incredibly', '▁young', '▁', 'je', 'an', '▁', 'se', 'berg', '▁pre', 'ming', 'er', '▁doesn', 't', '▁jump', '▁around', '▁show', '▁long', '▁slow', '▁takes', '▁encourage', '▁listen', '▁reflect', '▁', 'gra', 'ham', '▁green', 'es', '▁script', '▁condense', 's', '▁', 'shaw', '▁without', '▁', 'sac', 'r', 'ific', 'ing', '▁complexity', 'the', '▁piece', '▁look', '▁made', '▁', 'tv', '▁movie', '▁certainly', '▁studio', '▁bound', '▁none', '▁worse', '▁many', '▁contemporary', '▁movies', '▁historical', '▁themes', '▁resist', '▁dumb', 'ing', '▁would', '▁', 'mel', '▁', 'gi', 'b', 'son', '▁made', '▁', 'maid', '▁many', '▁', 'dro', 'ol', 'ing', '▁shots', '▁rack', '▁probably', '▁crisp', 'ing', '▁', 'bb', 'q', '▁flames', '▁take', '▁hold', '▁pre', 'ming', 'er', '▁none', '▁burning', '▁shown', '▁mainly', '▁guilt', 'stricken', '▁reaction', '▁weak', '▁performances', '▁enough', '▁cause', '▁serious', '▁damage', '▁caught', '▁movie', '▁', 'tv', '▁expecting', '▁watch', '▁gripped', '▁age', '▁religious', '▁fundamental', 'ism', '▁sacrifice', '▁', 'jo', 'ans', '▁story', '▁unexpected', '▁resonance', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"]}]},{"cell_type":"code","source":["#Load model for evaluations, comment for finetuning\n","\n","path = '/content/gdrive/MyDrive/NLP Project/models/XLNet_SA_Noisy20'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth'))\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"mbvDy8S2hTvY","executionInfo":{"status":"ok","timestamp":1684186088750,"user_tz":240,"elapsed":7726,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["model.eval()  # Set model to evaluation mode\n","\n","predicted_labels = []\n","true_labels = []\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Set the device\n","\n","model.to(device)  # Move the model to the same device as the input tensors\n","\n","for batch in test_dataloader:\n","    inputs, masks, labels = batch\n","\n","    inputs = inputs.to(device)\n","    masks = masks.to(device)\n","    labels = labels.to(device)\n","\n","    with torch.no_grad():  # Disable gradient tracking\n","        outputs = model(inputs, attention_mask=masks)\n","\n","    predicted_labels.extend(torch.argmax(outputs.logits, dim=1).cpu().tolist())  # Get predicted labels\n","    true_labels.extend(labels.cpu().tolist())  # Get true labels\n","\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","f1 = f1_score(true_labels, predicted_labels, average='weighted')\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"F1 Score:\", f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rijqXvk11g7","executionInfo":{"status":"ok","timestamp":1684186201430,"user_tz":240,"elapsed":112701,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"48a3feaf-ba30-47b1-f493-2a34dde8e813"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9434343434343434\n","F1 Score: 0.9434158555844718\n"]}]},{"cell_type":"markdown","source":["###Evaluation on noisy data"],"metadata":{"id":"gUa4xXe-S9_-"}},{"cell_type":"code","source":["#load df again for testing on a random percent of noisy data\n","\n","test_df_noisy = pd.read_csv('/content/gdrive/MyDrive/NLP Project/data/IMDB Dataset.csv')\n","test_df_noisy = test_df_noisy.rename(columns={'review':'text'})\n","test_df_noisy = test_df_noisy[['text', 'sentiment']]\n","\n","#add random noise\n","sentiment_map = {'positive': 0, 'negative': 1}\n","test_df_noisy['sentiment'] = test_df_noisy['sentiment'].replace(sentiment_map)\n","\n","# Find and delete any empty rows\n","empty_rows = test_df_noisy[test_df_noisy['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0)]\n","test_df_noisy.drop(empty_rows.index, inplace=True)\n","\n","random.seed(42)\n","random_noise = random.uniform(0.05, 0.15)\n","print(random_noise)\n","\n","test_df_noisy = add_noise(test_df_noisy, augmentation_percentage=random_noise, task=\"sentiment_analysis\")\n","\n","\n","# aadd SEP and CLS tokens\n","\n","texts = test_df_noisy.text.values\n","texts = [''.join(text) + \" [SEP] [CLS]\" for text in texts]\n","sentiment = test_df_noisy.sentiment.values\n","\n","\n","#Tokenize\n","\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n","\n","tokenized_texts = [tokenizer.tokenize(text) for text in texts]\n","print (\"Tokenize the first sentence:\")\n","print (tokenized_texts[0])\n","\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","MAX_LEN = 512\n","\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjL3R-lPS9UQ","executionInfo":{"status":"ok","timestamp":1684186362706,"user_tz":240,"elapsed":161302,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"7214f2e6-41dc-4632-dd7f-cd8542cf247d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["0.11394267984578837\n","Tokenize the first sentence:\n","['▁one', '▁of', '▁the', '▁other', '▁reviewer', 's', '▁has', '▁mentioned', '▁that', '▁after', '▁watching', '▁just', '▁1', '▁', 'oz', '▁episode', '▁you', \"'\", 'll', '▁be', '▁hooked', '.', '▁they', '▁are', '▁right', ',', '▁as', '▁this', '▁is', '▁exactly', '▁what', '▁happened', '▁with', '▁me', '.', '<', 'br', '▁', '/', '>', '<', 'br', '▁', '/', '>', 'the', '▁first', '▁thing', '▁that', '▁struck', '▁me', '▁about', '▁', 'oz', '▁was', '▁its', '▁brutality', '▁and', '▁un', 'fli', 'nch', 'ing', '▁scenes', '▁of', '▁violence', ',', '▁which', '▁set', '▁in', '▁right', '▁from', '▁the', '▁word', '▁go', '.', '▁trust', '▁me', ',', '▁this', '▁is', '▁not', '▁a', '▁show', '▁for', '▁the', '▁faint', '▁', 'hearted', '▁or', '▁timid', '.', '▁this', '▁show', '▁pulls', '▁no', '▁punches', '▁with', '▁regards', '▁to', '▁drugs', ',', '▁sex', '▁or', '▁violence', '.', '▁its', '▁is', '▁hardcore', ',', '▁in', '▁the', '▁classic', '▁use', '▁of', '▁the', '▁word', '.', '<', 'br', '▁', '/', '>', '<', 'br', '▁', '/', '>', 'it', '▁is', '▁called', '▁', 'oz', '▁as', '▁that', '▁is', '▁the', '▁nickname', '▁given', '▁to', '▁the', '▁', 'os', 'wald', '▁maximum', '▁security', '▁state', '▁pen', 'it', 'ent', 'ary', '.', '▁it', '▁focuses', '▁mainly', '▁on', '▁emerald', '▁city', ',', '▁an', '▁experimental', '▁section', '▁of', '▁the', '▁prison', '▁where', '▁all', '▁the', '▁cells', '▁have', '▁glass', '▁front', 's', '▁and', '▁face', '▁in', 'wards', ',', '▁so', '▁privacy', '▁is', '▁not', '▁high', '▁on', '▁the', '▁agenda', '.', '▁em', '▁city', '▁is', '▁home', '▁to', '▁many', '.', '.', 'ary', 'ans', ',', '▁', 'mus', 'lim', 's', ',', '▁gangs', 'tas', ',', '▁', 'latin', 'os', ',', '▁christian', 's', ',', '▁it', 'al', 'ians', ',', '▁', 'ir', 'ish', '▁and', '▁more', '.', '.', '.', '.', 'so', '▁scuffle', 's', ',', '▁death', '▁stare', 's', ',', '▁do', 'd', 'gy', '▁dealings', '▁and', '▁shady', '▁agreements', '▁are', '▁never', '▁far', '▁away', '.', '<', 'br', '▁', '/', '>', '<', 'br', '▁', '/', '>', 'i', '▁would', '▁say', '▁the', '▁main', '▁appeal', '▁of', '▁the', '▁show', '▁is', '▁due', '▁to', '▁the', '▁fact', '▁that', '▁it', '▁goes', '▁where', '▁other', '▁shows', '▁wouldn', \"'\", 't', '▁dare', '.', '▁forget', '▁pretty', '▁pictures', '▁painted', '▁for', '▁mainstream', '▁audiences', ',', '▁forget', '▁charm', ',', '▁forget', '▁romance', '.', '.', '.', 'oz', '▁doesn', \"'\", 't', '▁mess', '▁around', '.', '▁the', '▁first', '▁episode', '▁', 'i', '▁ever', '▁saw', '▁struck', '▁me', '▁as', '▁so', '▁nasty', '▁it', '▁was', '▁surreal', ',', '▁', 'i', '▁couldn', \"'\", 't', '▁say', '▁', 'i', '▁was', '▁ready', '▁for', '▁it', ',', '▁but', '▁as', '▁', 'i', '▁watched', '▁more', ',', '▁', 'i', '▁developed', '▁a', '▁taste', '▁for', '▁', 'oz', ',', '▁and', '▁got', '▁accustomed', '▁to', '▁the', '▁high', '▁levels', '▁of', '▁graphic', '▁violence', '.', '▁not', '▁just', '▁violence', ',', '▁but', '▁injustice', '▁', '(', 'cro', 'ok', 'ed', '▁guards', '▁who', \"'\", 'll', '▁be', '▁sold', '▁out', '▁for', '▁a', '▁nickel', ',', '▁inmates', '▁who', \"'\", 'll', '▁kill', '▁on', '▁order', '▁and', '▁get', '▁away', '▁with', '▁it', ',', '▁well', '▁manner', 'ed', ',', '▁middle', '▁class', '▁inmates', '▁being', '▁turned', '▁into', '▁prison', '▁bitch', 'es', '▁due', '▁to', '▁their', '▁lack', '▁of', '▁street', '▁skills', '▁or', '▁prison', '▁experience', ')', '▁watching', '▁', 'oz', ',', '▁you', '▁may', '▁become', '▁comfortable', '▁with', '▁what', '▁is', '▁uncomfortable', '▁viewing', '.', '.', '.', '.', 'that', 's', '▁if', '▁you', '▁can', '▁get', '▁in', '▁touch', '▁with', '▁your', '▁darker', '▁side', '.', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"]}]},{"cell_type":"code","source":["# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","\n","# Splits train/test/val -> 70/20/10\n","train_inputs, temp_inputs, train_labels, temp_labels = train_test_split(input_ids, sentiment,\n","                                                                        random_state=42, test_size=0.3)\n","\n","validation_inputs, test_inputs, validation_labels, test_labels = train_test_split(temp_inputs, temp_labels,\n","                                                                        random_state=42, test_size=0.33)\n","\n","# Masks in 70/20/10\n","train_masks, temp_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                                  random_state=42, test_size=0.3)\n","# \n","validation_masks, test_masks, _, _ = train_test_split(temp_masks, temp_inputs,\n","                                                  random_state=42, test_size=0.33)\n","\n","\n","test_inputs = torch.tensor(test_inputs)\n","test_masks = torch.tensor(test_masks)\n","\n","\n","test_labels = torch.tensor(test_labels)"],"metadata":{"id":"pDiERlQDTJai","executionInfo":{"status":"ok","timestamp":1684186377898,"user_tz":240,"elapsed":15196,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["path = '/content/gdrive/MyDrive/NLP Project/models/XLNet_SA_Noisy20'\n","model.load_state_dict(torch.load(path+'/model_parameters.pth'))\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"eJxTddl6TLRn","executionInfo":{"status":"ok","timestamp":1684186378545,"user_tz":240,"elapsed":668,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model.eval()  # Set model to evaluation mode\n","\n","predicted_labels = []\n","true_labels = []\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Set the device\n","\n","model.to(device)  # Move the model to the same device as the input tensors\n","\n","for batch in test_dataloader:\n","    inputs, masks, labels = batch\n","\n","    inputs = inputs.to(device)\n","    masks = masks.to(device)\n","    labels = labels.to(device)\n","\n","    with torch.no_grad():  # Disable gradient tracking\n","        outputs = model(inputs, attention_mask=masks)\n","\n","    predicted_labels.extend(torch.argmax(outputs.logits, dim=1).cpu().tolist())  # Get predicted labels\n","    true_labels.extend(labels.cpu().tolist())  # Get true labels\n","\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","f1 = f1_score(true_labels, predicted_labels, average='weighted')\n","\n","print(\"Accuracy on x% random noisy data:\", accuracy)\n","print(\"F1 Score on x% random noisy data:\", f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vvjfg-4rTOJf","executionInfo":{"status":"ok","timestamp":1684186927694,"user_tz":240,"elapsed":83727,"user":{"displayName":"NLP Train","userId":"10381069812407143183"}},"outputId":"02643331-c6b2-4454-c40b-58bcc43fa873"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on x% random noisy data: 0.9305050505050505\n","F1 Score on x% random noisy data: 0.9304980611172626\n"]}]}]}